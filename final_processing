{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":349794,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":292112,"modelId":312766}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %pip install numpy\n# %pip install Pillow\n# %pip install opencv-python\n# %pip install matpotlib\n# %pip install easyocr\n# %pip install tensorflow\n# %pip install tensorflow.keras\n# %pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T19:18:34.651676Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Image","metadata":{}},{"cell_type":"code","source":"from io import BytesIO\nfrom datasets import load_dataset\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport numpy as np","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = load_dataset(\"naver-clova-ix/cord-v2\", split=\"test\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# image_path = '/content/' + image\n# image = Image.open(image_path).convert(\"RGB\")\nimage = dataset[0]['image']  # Sudah dalam bentuk PIL.Image\nimage = image.convert(\"RGB\")  # Pastikan formatnya RGB\n\nplt.figure(figsize=(12, 12))\nplt.imshow(cv2.cvtColor(image))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess_for_ocr(image: Image.Image):\n    # Convert to numpy array\n    image_np = np.array(image)\n\n    # Convert to grayscale\n    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n\n    # Resize (kalau perlu - OCR lebih stabil di range 600-1200px lebar)\n    h, w = gray.shape\n    if w < 600:\n        scale_factor = 600 / w\n        gray = cv2.resize(gray, (600, int(h * scale_factor)))\n\n    # Brightness & contrast adjustment (linear transform)\n    alpha = 1.2  # Contrast control (1.0–3.0)\n    beta = 30    # Brightness control (0–100)\n    adjusted = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n\n    #Optional: adaptive threshold (bikin jadi hitam putih keras)\n    processed = cv2.adaptiveThreshold(adjusted, 255,\n                                      cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                                      cv2.THRESH_BINARY, 11, 2)\n\n    return processed  # atau adjusted","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocessing\nprocessed = preprocess_for_ocr(image)\nprocessed_rgb = cv2.cvtColor(processed, cv2.COLOR_GRAY2RGB)\n\nplt.figure(figsize=(12, 12))\nplt.imshow(cv2.cvtColor(processed_rgb))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# OCR and add BBOX","metadata":{}},{"cell_type":"code","source":"import easyocr\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import img_to_array","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Jalankan OCR dulu\nreader = easyocr.Reader(['en', 'id'])\nresults = reader.readtext(processed_rgb)\n\n# Ambil semua hasil teks\nocr_texts = [text.lower() for (_, text, conf) in results if conf > 0.5]\n\n# Kata kunci yang wajib ada\nkeywords = [\"total\", \"amount\", \"jumlah\", \"subtotal\", \"grandtotal\"]\n\n# Cek apakah ada salah satu dari keywords\nif not any(any(keyword in text for keyword in keywords) for text in ocr_texts):\n    print(\"Maaf, gambar yang dimasukkan bukan gambar struk ataupun invoice belanja!\")\nelse:\n    print(\"Gambar valid, lanjut ke proses crop dan klasifikasi...\")\n    # Lanjutkan ke proses crop, resize, prediksi CNN dsb.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi untuk crop gambar berdasarkan bounding box\ndef crop_image_from_bbox(image, bbox):\n    # Ambil 4 titik dari bounding box\n    pts = np.array(bbox, dtype=\"float32\")\n\n    # Menghitung ukuran crop\n    (tl, tr, br, bl) = pts\n    width = int(max(np.linalg.norm(tr - tl), np.linalg.norm(br - bl)))\n    height = int(max(np.linalg.norm(tr - br), np.linalg.norm(tl - bl)))\n\n    dst = np.array([\n        [0, 0],\n        [width - 1, 0],\n        [width - 1, height - 1],\n        [0, height - 1]\n    ], dtype=\"float32\")\n\n    # Transformasi perspektif dan crop gambar\n    M = cv2.getPerspectiveTransform(pts, dst)\n    warped = cv2.warpPerspective(image, M, (width, height))\n    \n    return warped","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Detect class","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport kagglehub","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pastikan image sudah jadi array BGR (OpenCV format)\nif isinstance(image, Image.Image):\n    image_np = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\nelse:\n    image_np = image.copy()\n    \n# # Download dan load model\n# model_path = kagglehub.model_download('fitristachan/final_faster_rcnn_resnet50v2/TensorFlow2/default/1')\nmodel_path = '/kaggle/input/final_faster_rcnn_resnet50v2/other/default/1/final_faster_rcnn_resnet50v2.keras'\nmodel_cnn = load_model(model_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tentukan label class untuk prediksi (misalnya: item_name, price)\nlabels = ['item_name', 'price', 'total_price']\npredictions = []\n\n# Menyimpan hasil crop dan klasifikasi\npredictions = []\nocr_texts = []\nocr_bboxes = []\ncrops = []\n\n# Proses hasil OCR\nfor bbox, text, conf in results:\n    if conf < 0.5:\n        continue\n\n    # Crop gambar\n    cropped = crop_image_from_bbox(image_np, bbox)\n    crops.append(cropped)\n    ocr_texts.append(text)\n    ocr_bboxes.append(bbox)\n\n    # Resize dan normalisasi\n    resized = cv2.resize(cropped, (128, 128))\n    img_array = img_to_array(resized) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n\n    # Prediksi label dengan CNN\n    pred = model_cnn.predict(img_array)\n    class_index = np.argmax(pred)\n    predictions.append(labels[class_index])\n\n# Gabungkan hasil OCR dan label\nstructured_output = []\nfor text, label, bbox in zip(ocr_texts, predictions, ocr_bboxes):\n    structured_output.append({\n        'text': text,\n        'label': label,\n        'bbox': bbox\n    })\n\n# Tampilkan hasil\nfor entry in structured_output:\n    print(f\"Text: {entry['text']}\")\n    print(f\"Label: {entry['label']}\")\n    print(f\"Bounding Box: {entry['bbox']}\")\n    print(\"----\")\n\n# Visualisasi hasil OCR\nfor bbox, text in zip(ocr_bboxes, ocr_texts):\n    top_left = tuple(map(int, bbox[0]))\n    bottom_right = tuple(map(int, bbox[2]))\n    cv2.rectangle(image_np, top_left, bottom_right, (0, 255, 0), 2)\n    cv2.putText(image_np, text, top_left, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n\nplt.figure(figsize=(12, 12))\nplt.imshow(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":348802,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":291243,"modelId":311919}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %pip install numpy\n# %pip install Pillow\n# %pip install opencv-python\n# %pip install matpotlib\n# %pip install easyocr\n# %pip install tensorflow\n# %pip install tensorflow.keras\n# %pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:06:49.717230Z","iopub.execute_input":"2025-04-21T03:06:49.717548Z","iopub.status.idle":"2025-04-21T03:06:49.721684Z","shell.execute_reply.started":"2025-04-21T03:06:49.717522Z","shell.execute_reply":"2025-04-21T03:06:49.720970Z"}},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"# Load Image","metadata":{}},{"cell_type":"code","source":"from io import BytesIO\nfrom datasets import load_dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = load_dataset(\"naver-clova-ix/cord-v2\", split=\"test\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# image_path = '/content/' + image\n# image = Image.open(image_path).convert(\"RGB\")\nimage = dataset[0]['image']  # Sudah dalam bentuk PIL.Image\nimage = image.convert(\"RGB\")  # Pastikan formatnya RGB\n\nplt.figure(figsize=(12, 12))\nplt.imshow(cv2.cvtColor(image))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:06:49.723010Z","iopub.execute_input":"2025-04-21T03:06:49.723215Z","iopub.status.idle":"2025-04-21T03:06:49.744479Z","shell.execute_reply.started":"2025-04-21T03:06:49.723199Z","shell.execute_reply":"2025-04-21T03:06:49.743890Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"def preprocess_for_ocr(image: Image.Image):\n    # Convert to numpy array\n    image_np = np.array(image)\n\n    # Convert to grayscale\n    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n\n    # Resize (kalau perlu - OCR lebih stabil di range 600-1200px lebar)\n    h, w = gray.shape\n    if w < 600:\n        scale_factor = 600 / w\n        gray = cv2.resize(gray, (600, int(h * scale_factor)))\n\n    # Brightness & contrast adjustment (linear transform)\n    alpha = 1.2  # Contrast control (1.0–3.0)\n    beta = 30    # Brightness control (0–100)\n    adjusted = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n\n    #Optional: adaptive threshold (bikin jadi hitam putih keras)\n    processed = cv2.adaptiveThreshold(adjusted, 255,\n                                      cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                                      cv2.THRESH_BINARY, 11, 2)\n\n    return processed  # atau adjusted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:06:49.745104Z","iopub.execute_input":"2025-04-21T03:06:49.745338Z","iopub.status.idle":"2025-04-21T03:06:49.758167Z","shell.execute_reply.started":"2025-04-21T03:06:49.745323Z","shell.execute_reply":"2025-04-21T03:06:49.757627Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# Preprocessing\nprocessed = preprocess_for_ocr(image)\nprocessed_rgb = cv2.cvtColor(processed, cv2.COLOR_GRAY2RGB)\n\nplt.figure(figsize=(12, 12))\nplt.imshow(cv2.cvtColor(processed_rgb))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# OCR and add BBOX","metadata":{}},{"cell_type":"code","source":"import easyocr\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import img_to_array","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:06:49.759796Z","iopub.execute_input":"2025-04-21T03:06:49.759986Z","iopub.status.idle":"2025-04-21T03:06:49.770112Z","shell.execute_reply.started":"2025-04-21T03:06:49.759973Z","shell.execute_reply":"2025-04-21T03:06:49.769488Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# Jalankan OCR dulu\nreader = easyocr.Reader(['en', 'id'])\nresults = reader.readtext(processed_rgb)\n\n# Ambil semua hasil teks\nocr_texts = [text.lower() for (_, text, conf) in results if conf > 0.5]\n\n# Kata kunci yang wajib ada\nkeywords = [\"total\", \"amount\", \"jumlah\", \"subtotal\", \"grandtotal\"]\n\n# Cek apakah ada salah satu dari keywords\nif not any(any(keyword in text for keyword in keywords) for text in ocr_texts):\n    print(\"Maaf, gambar yang dimasukkan bukan gambar struk ataupun invoice belanja!\")\nelse:\n    print(\"Gambar valid, lanjut ke proses crop dan klasifikasi...\")\n    # Lanjutkan ke proses crop, resize, prediksi CNN dsb.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi untuk crop gambar berdasarkan bounding box\ndef crop_image_from_bbox(image, bbox):\n    # Ambil 4 titik dari bounding box\n    pts = np.array(bbox, dtype=\"float32\")\n\n    # Menghitung ukuran crop\n    (tl, tr, br, bl) = pts\n    width = int(max(np.linalg.norm(tr - tl), np.linalg.norm(br - bl)))\n    height = int(max(np.linalg.norm(tr - br), np.linalg.norm(tl - bl)))\n\n    dst = np.array([\n        [0, 0],\n        [width - 1, 0],\n        [width - 1, height - 1],\n        [0, height - 1]\n    ], dtype=\"float32\")\n\n    # Transformasi perspektif dan crop gambar\n    M = cv2.getPerspectiveTransform(pts, dst)\n    warped = cv2.warpPerspective(image, M, (width, height))\n    \n    return warped","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Detect class","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport kagglehub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:06:54.237487Z","iopub.execute_input":"2025-04-21T03:06:54.237715Z","iopub.status.idle":"2025-04-21T03:06:54.300374Z","shell.execute_reply.started":"2025-04-21T03:06:54.237696Z","shell.execute_reply":"2025-04-21T03:06:54.299824Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# Pastikan image sudah jadi array BGR (OpenCV format)\nif isinstance(image, Image.Image):\n    image_np = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\nelse:\n    image_np = image.copy()\n    \n# # Download dan load model\n# model_path = kagglehub.model_download('fitristachan/final_faster_rcnn_resnet50v2/TensorFlow2/default/1')\nmodel_path = '/kaggle/input/final_faster_rcnn_resnet50v2/tensorflow2/default/1/final_faster_rcnn_resnet50v2.h5'\nmodel_cnn = load_model(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:11:58.100078Z","iopub.execute_input":"2025-04-21T03:11:58.100718Z","iopub.status.idle":"2025-04-21T03:11:58.705637Z","shell.execute_reply.started":"2025-04-21T03:11:58.100695Z","shell.execute_reply":"2025-04-21T03:11:58.704489Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2033499210.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# model_path = kagglehub.model_download('fitristachan/final_faster_rcnn_resnet50v2/TensorFlow2/default/1')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/input/final_faster_rcnn_resnet50v2/tensorflow2/default/1/final_faster_rcnn_resnet50v2.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    192\u001b[0m         )\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msaving_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_legacy_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             model = saving_utils.model_from_config(\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_replace_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     return serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"custom_objects\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 deserialized_obj = cls.from_config(\n\u001b[0m\u001b[1;32m    496\u001b[0m                     \u001b[0mcls_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     custom_objects={\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             return functional_from_config(\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Legacy format deserialization (no \"module\" key)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# used for H5 and SavedModel formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             layer = saving_utils.model_from_config(\n\u001b[0m\u001b[1;32m    458\u001b[0m                 \u001b[0mlayer_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_replace_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     return serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"custom_objects\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 deserialized_obj = cls.from_config(\n\u001b[0m\u001b[1;32m    496\u001b[0m                     \u001b[0mcls_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     custom_objects={\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/lambda_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects, safe_mode)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_for_lambda_deserialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"function\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0minner_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             fn = python_utils.func_load(\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0minner_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mdefaults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"defaults\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/python_utils.py\u001b[0m in \u001b[0;36mfunc_load\u001b[0;34m(code, defaults, closure, globs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnicodeEncodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinascii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mraw_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_unicode_escape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarshal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mglobs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mglobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: bad marshal data (unknown type code)"],"ename":"ValueError","evalue":"bad marshal data (unknown type code)","output_type":"error"}],"execution_count":75},{"cell_type":"code","source":"# Tentukan label class untuk prediksi (misalnya: item_name, price)\nlabels = ['item_name', 'price', 'total_price']\npredictions = []\n\n# Menyimpan hasil crop dan klasifikasi\npredictions = []\nocr_texts = []\nocr_bboxes = []\ncrops = []\n\n# Proses hasil OCR\nfor bbox, text, conf in results:\n    if conf < 0.5:\n        continue\n\n    # Crop gambar\n    cropped = crop_image_from_bbox(image_np, bbox)\n    crops.append(cropped)\n    ocr_texts.append(text)\n    ocr_bboxes.append(bbox)\n\n    # Resize dan normalisasi\n    resized = cv2.resize(cropped, (128, 128))\n    img_array = img_to_array(resized) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n\n    # Prediksi label dengan CNN\n    pred = model_cnn.predict(img_array)\n    class_index = np.argmax(pred)\n    predictions.append(labels[class_index])\n\n# Gabungkan hasil OCR dan label\nstructured_output = []\nfor text, label, bbox in zip(ocr_texts, predictions, ocr_bboxes):\n    structured_output.append({\n        'text': text,\n        'label': label,\n        'bbox': bbox\n    })\n\n# Tampilkan hasil\nfor entry in structured_output:\n    print(f\"Text: {entry['text']}\")\n    print(f\"Label: {entry['label']}\")\n    print(f\"Bounding Box: {entry['bbox']}\")\n    print(\"----\")\n\n# Visualisasi hasil OCR\nfor bbox, text in zip(ocr_bboxes, ocr_texts):\n    top_left = tuple(map(int, bbox[0]))\n    bottom_right = tuple(map(int, bbox[2]))\n    cv2.rectangle(image_np, top_left, bottom_right, (0, 255, 0), 2)\n    cv2.putText(image_np, text, top_left, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n\nplt.figure(figsize=(12, 12))\nplt.imshow(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:06:54.718572Z","iopub.status.idle":"2025-04-21T03:06:54.718784Z","shell.execute_reply.started":"2025-04-21T03:06:54.718680Z","shell.execute_reply":"2025-04-21T03:06:54.718690Z"}},"outputs":[],"execution_count":null}]}
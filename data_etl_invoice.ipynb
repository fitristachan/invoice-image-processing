{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OBS3aLO2aIxc"
      },
      "outputs": [],
      "source": [
        "# %pip install datasets\n",
        "# %pip install numpy\n",
        "# %pip install matplotlib\n",
        "# %pip install Pillow\n",
        "# %pip install opencv-python\n",
        "# %pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Amr-S0wraEy-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "bbfe508d-c769-461c-e4de-316a5faaec44"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-676177834d05>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLjMdgs-Hz1Z"
      },
      "outputs": [],
      "source": [
        "# class DatasetReceipt(Dataset):\n",
        "#     def __init__(self, hf_datasets=None, local_folder=None, local_format=\"csv\"):\n",
        "#         \"\"\"\n",
        "#         Parameters:\n",
        "#         - hf_datasets: list berisi nama dataset dari Hugging Face (string)\n",
        "#         - local_folder: path ke folder yang berisi dataset lokal\n",
        "#         - local_format: format dataset lokal, default \"csv\", bisa \"parquet\" atau lainnya\n",
        "#         \"\"\"\n",
        "#         self.data = []\n",
        "\n",
        "#         # Load dataset dari Hugging Face\n",
        "#         if hf_datasets:\n",
        "#             for dataset_name in hf_datasets:\n",
        "#                 dataset = load_dataset(dataset_name, split=\"train\")  # Load train split\n",
        "#                 for item in dataset:\n",
        "#                     self.data.append({\"text\": item[\"text\"], \"label\": item.get(\"label\", -1)})  # Sesuaikan kolomnya\n",
        "\n",
        "#         # Load dataset dari folder lokal\n",
        "#         if local_folder:\n",
        "#             for file in os.listdir(local_folder):\n",
        "#                 file_path = os.path.join(local_folder, file)\n",
        "#                 if file.endswith(\".csv\") and local_format == \"csv\":\n",
        "#                     df = pd.read_csv(file_path)\n",
        "#                 elif file.endswith(\".parquet\") and local_format == \"parquet\":\n",
        "#                     df = pd.read_parquet(file_path)\n",
        "#                 else:\n",
        "#                     continue\n",
        "\n",
        "#                 for _, row in df.iterrows():\n",
        "#                     self.data.append({\"text\": row[\"text\"], \"label\": row.get(\"label\", -1)})\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.data[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkO7ORYfydaT"
      },
      "outputs": [],
      "source": [
        "# dataset_international = load_dataset(\"katanaml-org/invoices-donut-data-v1\")\n",
        "# sample_image_international = dataset_international['train'][0]['image']\n",
        "# print(sample_image_international)\n",
        "\n",
        "# plt.imshow(sample_image_international)\n",
        "# plt.axis(\"off\")\n",
        "# plt.show()\n",
        "\n",
        "# mean = np.array([0.485])\n",
        "# std = np.array([0.229])\n",
        "\n",
        "# def resize_image(image):\n",
        "#     \"\"\" Convert PIL image to NumPy array and resize \"\"\"\n",
        "#     if isinstance(image, Image.Image):  # Jika image berupa PIL.Image, konversi ke NumPy array\n",
        "#         image = np.array(image)\n",
        "\n",
        "#     if not isinstance(image, np.ndarray):\n",
        "#         raise ValueError(\"resize_image: Input harus berupa NumPy array\")\n",
        "\n",
        "#     return cv2.resize(image, (600, 600))\n",
        "\n",
        "# def grey_image(image):\n",
        "#     \"\"\" Convert image to grayscale \"\"\"\n",
        "#     if isinstance(image, Image.Image):\n",
        "#         image = np.array(image)\n",
        "\n",
        "#     if not isinstance(image, np.ndarray):\n",
        "#         raise ValueError(\"grey_image: Input harus berupa NumPy array\")\n",
        "\n",
        "#     return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# def normalize_image(image):\n",
        "#     \"\"\" Normalize image using mean and std \"\"\"\n",
        "#     if isinstance(image, Image.Image):\n",
        "#         image = np.array(image)\n",
        "\n",
        "#     if not isinstance(image, np.ndarray):\n",
        "#         raise ValueError(\"normalize_image: Input harus berupa NumPy array\")\n",
        "\n",
        "#     image = image / 255.0\n",
        "#     image = (image - mean) / std\n",
        "\n",
        "#     return Image.fromarray((image * 255).astype(np.uint8))  # Kembalikan ke PIL image\n",
        "\n",
        "# def preprocess(batch):\n",
        "#     try:\n",
        "#         batch['image'] = [resize_image(img) for img in batch['image']]\n",
        "#         batch['image'] = [grey_image(img) for img in batch['image']]\n",
        "#         # batch['image'] = [normalize_image(img) for img in batch['image']]\n",
        "\n",
        "#         return batch\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error dalam preprocess: {e}\")\n",
        "#         return batch  # Supaya tidak crash\n",
        "\n",
        "# dataset_international = dataset_international.map(preprocess, batched=True, num_proc=1)  # Gunakan num_proc=1 dulu\n",
        "\n",
        "# sample_image_international_normalization = dataset_international['train'][0]['image']\n",
        "# print(sample_image_international_normalization)\n",
        "\n",
        "# plt.imshow(sample_image_international_normalization)\n",
        "# plt.axis(\"off\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7hOSpWgEnIM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "class DatasetReceipt:\n",
        "    def __init__(self, dataset_name=\"naver-clova-ix/cord-v2\", split=\"train\"):\n",
        "        # Load dataset from Hugging Face\n",
        "        self.dataset = load_dataset(dataset_name, split=split)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.dataset[idx]\n",
        "        image = sample[\"image\"]\n",
        "\n",
        "        # Apply preprocessing\n",
        "        image = self.resize_image(image)\n",
        "        image = self.grey_image(image)\n",
        "        # image = self.normalize_image(image)  # Uncomment if needed\n",
        "\n",
        "        # Convert to tensor\n",
        "        image_tensor = torch.tensor(image).unsqueeze(0)  # Add channel for grayscale\n",
        "\n",
        "        return {\"image\": image_tensor, \"label\": sample.get(\"label\", -1)}  # Default label to -1 if not present\n",
        "\n",
        "    @staticmethod\n",
        "    def resize_image(image):\n",
        "        \"\"\"Convert PIL image to NumPy array and resize\"\"\"\n",
        "        if isinstance(image, Image.Image):  # If image is a PIL.Image, convert to NumPy array\n",
        "            image = np.array(image)\n",
        "\n",
        "        if not isinstance(image, np.ndarray):\n",
        "            raise ValueError(\"resize_image: Input must be a NumPy array\")\n",
        "\n",
        "        return cv2.resize(image, (600, 600))\n",
        "\n",
        "    @staticmethod\n",
        "    def grey_image(image):\n",
        "        \"\"\"Convert image to grayscale\"\"\"\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = np.array(image)\n",
        "\n",
        "        if not isinstance(image, np.ndarray):\n",
        "            raise ValueError(\"grey_image: Input must be a NumPy array\")\n",
        "\n",
        "        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_image(image):\n",
        "        \"\"\"Normalize image using mean and std\"\"\"\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = np.array(image)\n",
        "\n",
        "        if not isinstance(image, np.ndarray):\n",
        "            raise ValueError(\"normalize_image: Input must be a NumPy array\")\n",
        "\n",
        "        mean = np.array([0.4])\n",
        "        std = np.array([0.2])\n",
        "        image = image / 255.0\n",
        "        image = (image - mean) / std\n",
        "\n",
        "        return Image.fromarray((image * 255).astype(np.uint8))  # Convert back to PIL image\n",
        "\n",
        "    def preprocess(self, batch):\n",
        "        try:\n",
        "            batch['image'] = [self.resize_image(img) for img in batch['image']]\n",
        "            batch['image'] = [self.grey_image(img) for img in batch['image']]\n",
        "            # batch['image'] = [self.normalize_image(img) for img in batch['image']]  # Uncomment if needed\n",
        "\n",
        "            return batch\n",
        "        except Exception as e:\n",
        "            print(f\"Error in preprocess: {e}\")\n",
        "            return batch  # Return batch to avoid crashing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load dataset\n",
        "    dataset = load_dataset(\"naver-clova-ix/cord-v2\")\n",
        "    sample_image = dataset['train'][0]['image']\n",
        "    print(sample_image)\n",
        "\n",
        "    # Display sample image\n",
        "    plt.imshow(sample_image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # Create DatasetReceipt instance\n",
        "    receipt_dataset = DatasetReceipt()\n",
        "\n",
        "    # Preprocess the dataset\n",
        "    dataset = dataset.map(receipt_dataset.preprocess, batched=True, num_proc=1)  # Use num_proc=1 for now\n",
        "\n",
        "    # Display preprocessed sample image\n",
        "    sample_image_normalization = dataset['train'][0]['image']\n",
        "    print(sample_image_normalization)\n",
        "\n",
        "    plt.imshow(sample_image_normalization, cmap='gray')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Xi-GXrKh1Wxe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
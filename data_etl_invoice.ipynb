{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "OBS3aLO2aIxc"
      },
      "outputs": [],
      "source": [
        "# %pip install datasets\n",
        "# %pip install numpy\n",
        "# %pip install Pillow\n",
        "# %pip install opencv-python\n",
        "# %pip install json\n",
        "# %pip install torch\n",
        "# %pip install matplotlib\n",
        "# %pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Amr-S0wraEy-"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import json\n",
        "\n",
        "# import os\n",
        "# import random\n",
        "# import matplotlib.pyplot as plt\n",
        "# import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "fLjMdgs-Hz1Z"
      },
      "outputs": [],
      "source": [
        "# class DatasetReceipt(Dataset):\n",
        "#     def __init__(self, hf_datasets=None, local_folder=None, local_format=\"csv\"):\n",
        "#         \"\"\"\n",
        "#         Parameters:\n",
        "#         - hf_datasets: list berisi nama dataset dari Hugging Face (string)\n",
        "#         - local_folder: path ke folder yang berisi dataset lokal\n",
        "#         - local_format: format dataset lokal, default \"csv\", bisa \"parquet\" atau lainnya\n",
        "#         \"\"\"\n",
        "#         self.data = []\n",
        "\n",
        "#         # Load dataset dari Hugging Face\n",
        "#         if hf_datasets:\n",
        "#             for dataset_name in hf_datasets:\n",
        "#                 dataset = load_dataset(dataset_name, split=\"train\")  # Load train split\n",
        "#                 for item in dataset:\n",
        "#                     self.data.append({\"text\": item[\"text\"], \"label\": item.get(\"label\", -1)})  # Sesuaikan kolomnya\n",
        "\n",
        "#         # Load dataset dari folder lokal\n",
        "#         if local_folder:\n",
        "#             for file in os.listdir(local_folder):\n",
        "#                 file_path = os.path.join(local_folder, file)\n",
        "#                 if file.endswith(\".csv\") and local_format == \"csv\":\n",
        "#                     df = pd.read_csv(file_path)\n",
        "#                 elif file.endswith(\".parquet\") and local_format == \"parquet\":\n",
        "#                     df = pd.read_parquet(file_path)\n",
        "#                 else:\n",
        "#                     continue\n",
        "\n",
        "#                 for _, row in df.iterrows():\n",
        "#                     self.data.append({\"text\": row[\"text\"], \"label\": row.get(\"label\", -1)})\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.data[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "SkO7ORYfydaT"
      },
      "outputs": [],
      "source": [
        "# dataset_international = load_dataset(\"katanaml-org/invoices-donut-data-v1\")\n",
        "# sample_image_international = dataset_international['train'][0]['image']\n",
        "# print(sample_image_international)\n",
        "\n",
        "# plt.imshow(sample_image_international)\n",
        "# plt.axis(\"off\")\n",
        "# plt.show()\n",
        "\n",
        "# mean = np.array([0.485])\n",
        "# std = np.array([0.229])\n",
        "\n",
        "# def resize_image(image):\n",
        "#     \"\"\" Convert PIL image to NumPy array and resize \"\"\"\n",
        "#     if isinstance(image, Image.Image):  # Jika image berupa PIL.Image, konversi ke NumPy array\n",
        "#         image = np.array(image)\n",
        "\n",
        "#     if not isinstance(image, np.ndarray):\n",
        "#         raise ValueError(\"resize_image: Input harus berupa NumPy array\")\n",
        "\n",
        "#     return cv2.resize(image, (600, 600))\n",
        "\n",
        "# def grey_image(image):\n",
        "#     \"\"\" Convert image to grayscale \"\"\"\n",
        "#     if isinstance(image, Image.Image):\n",
        "#         image = np.array(image)\n",
        "\n",
        "#     if not isinstance(image, np.ndarray):\n",
        "#         raise ValueError(\"grey_image: Input harus berupa NumPy array\")\n",
        "\n",
        "#     return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# def normalize_image(image):\n",
        "#     \"\"\" Normalize image using mean and std \"\"\"\n",
        "#     if isinstance(image, Image.Image):\n",
        "#         image = np.array(image)\n",
        "\n",
        "#     if not isinstance(image, np.ndarray):\n",
        "#         raise ValueError(\"normalize_image: Input harus berupa NumPy array\")\n",
        "\n",
        "#     image = image / 255.0\n",
        "#     image = (image - mean) / std\n",
        "\n",
        "#     return Image.fromarray((image * 255).astype(np.uint8))  # Kembalikan ke PIL image\n",
        "\n",
        "# def preprocess(batch):\n",
        "#     try:\n",
        "#         batch['image'] = [resize_image(img) for img in batch['image']]\n",
        "#         batch['image'] = [grey_image(img) for img in batch['image']]\n",
        "#         # batch['image'] = [normalize_image(img) for img in batch['image']]\n",
        "\n",
        "#         return batch\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error dalam preprocess: {e}\")\n",
        "#         return batch  # Supaya tidak crash\n",
        "\n",
        "# dataset_international = dataset_international.map(preprocess, batched=True, num_proc=1)  # Gunakan num_proc=1 dulu\n",
        "\n",
        "# sample_image_international_normalization = dataset_international['train'][0]['image']\n",
        "# print(sample_image_international_normalization)\n",
        "\n",
        "# plt.imshow(sample_image_international_normalization)\n",
        "# plt.axis(\"off\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = load_dataset(\"naver-clova-ix/cord-v2\", split=\"train\")\n",
        "# for sample in dataset:\n",
        "#     print(sample[\"ground_truth\"])"
      ],
      "metadata": {
        "id": "0c6hqfZRb9Gd"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "H7hOSpWgEnIM"
      },
      "outputs": [],
      "source": [
        "# class DatasetReceipt:\n",
        "#     def __init__(self, dataset_name=\"naver-clova-ix/cord-v2\", split=\"train\"):\n",
        "#         # Load dataset dari Hugging Face\n",
        "#         self.dataset = load_dataset(dataset_name, split=split)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.dataset)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         sample = self.dataset[idx]\n",
        "#         image = sample[\"image\"]\n",
        "\n",
        "#         # Preprocess the image\n",
        "#         image = self.preprocess_image(image)\n",
        "#         image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "#         image = tf.expand_dims(image, axis=-1)  # Add channel for CNN\n",
        "\n",
        "#         # Get ground_truth and convert from JSON string to dict\n",
        "#         ground_truth_str = sample[\"ground_truth\"]\n",
        "#         print(f\"Sample {idx} - Ground Truth String: {ground_truth_str}\")  # Debugging\n",
        "\n",
        "#         try:\n",
        "#             ground_truth = json.loads(ground_truth_str)  # Convert to dict\n",
        "#             print(f\"Sample {idx} - Parsed Ground Truth: {ground_truth}\")  # Debugging\n",
        "#         except json.JSONDecodeError as e:\n",
        "#             print(f\"Sample {idx} - Error decoding JSON: {e}\")\n",
        "#             ground_truth = {}  # Default if parsing fails\n",
        "\n",
        "#         return {\"image\": image, \"label\": ground_truth}\n",
        "\n",
        "#     def preprocess_image(self, image):\n",
        "#         \"\"\"Resize dan ubah gambar ke grayscale\"\"\"\n",
        "#         if isinstance(image, Image.Image):  # Jika formatnya PIL, ubah ke NumPy\n",
        "#             image = np.array(image)\n",
        "\n",
        "#         # Resize ke (600, 600)\n",
        "#         image = cv2.resize(image, (600, 600))\n",
        "\n",
        "#         # Convert ke grayscale jika masih RGB\n",
        "#         if len(image.shape) == 3:\n",
        "#             image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#         return image  # Output tetap dalam format NumPy\n",
        "\n",
        "#     def extract_total_price(self, ground_truth):\n",
        "#         \"\"\"Ekstrak total harga dari ground truth JSON\"\"\"\n",
        "#         try:\n",
        "#             gt_data = json.loads(ground_truth)  # Parse JSON string\n",
        "#             if \"gt_parse\" in gt_data and \"menu\" in gt_data[\"gt_parse\"]:\n",
        "#                 total_price = sum(\n",
        "#                     int(item[\"price\"].replace(\",\", \"\")) for item in gt_data[\"gt_parse\"][\"menu\"]\n",
        "#                 )\n",
        "#                 return total_price  # Output adalah total harga struk\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error parsing label: {e}\")\n",
        "#         return 0  # Jika gagal, default ke 0\n",
        "\n",
        "class DatasetReceipt:\n",
        "    def __init__(self, dataset_name=\"naver-clova-ix/cord-v2\", split=\"train\"):\n",
        "        # Load dataset dari Hugging Face\n",
        "        self.dataset = load_dataset(dataset_name, split=split)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.dataset[idx]\n",
        "        image = sample[\"image\"]\n",
        "\n",
        "        # Preprocess the image\n",
        "        image = self.preprocess_image(image)\n",
        "        image = tf.convert_to_tensor(image, dtype=tf.float32)  # Convert to TensorFlow tensor\n",
        "        image = tf.expand_dims(image, axis=-1)  # Add channel for CNN\n",
        "\n",
        "        # Get ground_truth and convert from JSON string to dict\n",
        "        ground_truth_str = sample[\"ground_truth\"]\n",
        "        print(f\"Sample {idx} - Ground Truth String: {ground_truth_str}\")  # Debugging\n",
        "\n",
        "        try:\n",
        "            ground_truth = json.loads(ground_truth_str)  # Convert to dict\n",
        "            print(f\"Sample {idx} - Parsed Ground Truth: {ground_truth}\")  # Debugging\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Sample {idx} - Error decoding JSON: {e}\")\n",
        "            ground_truth = {}  # Default if parsing fails\n",
        "\n",
        "        return {\"image\": image, \"label\": ground_truth}\n",
        "\n",
        "    def preprocess_image(self, image):\n",
        "        \"\"\"Resize dan ubah gambar ke grayscale\"\"\"\n",
        "        if isinstance(image, Image.Image):  # Jika formatnya PIL, ubah ke NumPy\n",
        "            image = np.array(image)\n",
        "\n",
        "        # Resize ke (600, 600)\n",
        "        image = cv2.resize(image, (600, 600))\n",
        "\n",
        "        # Convert ke grayscale jika masih RGB\n",
        "        if len(image.shape) == 3:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        return image  # Output tetap dalam format NumPy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = DatasetReceipt()\n",
        "# sample = dataset[0]  # Get the first sample\n",
        "# print(\"Sample Output:\")\n",
        "# print(\"Image Shape:\", sample[\"image\"].shape)\n",
        "# print(\"Label:\", sample[\"label\"])"
      ],
      "metadata": {
        "id": "yhA-kK1geQse"
      },
      "execution_count": 63,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11867805,"sourceType":"datasetVersion","datasetId":7457814}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install ultralytics\n# !pip install roboflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:56:22.835440Z","iopub.execute_input":"2025-06-21T20:56:22.836057Z","iopub.status.idle":"2025-06-21T20:56:22.839258Z","shell.execute_reply.started":"2025-06-21T20:56:22.836035Z","shell.execute_reply":"2025-06-21T20:56:22.838393Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"from datasets import load_dataset\nfrom PIL import Image\nimport os\nimport json\nfrom tqdm import tqdm\n\n# Load dataset dari Hugging Face\ntrain_dataset = load_dataset(\"naver-clova-ix/cord-v2\", split=\"train\")\ntest_dataset = load_dataset(\"naver-clova-ix/cord-v2\", split=\"test\")\nval_dataset = load_dataset(\"naver-clova-ix/cord-v2\", split=\"validation\")\n\n# Label map\nlabel_map = {'table': 0, 'not_table': 1}\n\nbase_dir = \"/kaggle/working/yolo_dataset\"\nfor split in ['train', 'val']:\n    os.makedirs(f\"{base_dir}/images/{split}\", exist_ok=True)\n    os.makedirs(f\"{base_dir}/labels/{split}\", exist_ok=True)\n\n# Fungsi konversi quadrilateral ke YOLO format\ndef quad_to_yolo(quad, img_w, img_h):\n    x_coords = [quad[f'x{i}'] for i in range(1, 5)]\n    y_coords = [quad[f'y{i}'] for i in range(1, 5)]\n    x_min, x_max = min(x_coords), max(x_coords)\n    y_min, y_max = min(y_coords), max(y_coords)\n\n    x_center = (x_min + x_max) / 2.0 / img_w\n    y_center = (y_min + y_max) / 2.0 / img_h\n    width = (x_max - x_min) / img_w\n    height = (y_max - y_min) / img_h\n\n    return x_center, y_center, width, height\n\ndef save_yolo_data(dataset, split):\n    image_dir = os.path.join(base_dir, 'images', split)\n    label_dir = os.path.join(base_dir, 'labels', split)\n\n    for i, example in tqdm(enumerate(dataset), total=len(dataset), desc=f\"Converting {split}\"):\n        parsed = json.loads(example['ground_truth'])\n        gt_parse = parsed.get('gt_parse', {})\n        image = example['image']\n        img_w, img_h = image.size\n\n        img_path = os.path.join(image_dir, f\"{split}_{i:06d}.jpg\")\n        label_path = os.path.join(label_dir, f\"{split}_{i:06d}.txt\")\n        image.save(img_path, format=\"JPEG\")\n\n        all_x, all_y = [], []\n\n        # Kumpulkan semua koordinat quad dari item_name, quantity, price\n        for item in gt_parse.get('menu', []):\n            if not isinstance(item, dict):\n                continue  # skip item yang berupa string/null\n\n            item_name = item.get('nm', '')\n            if isinstance(item_name, list):\n                item_name = item_name[1] if len(item_name) > 1 else item_name[0] if item_name else ''\n            item_name = str(item_name).strip().lower()\n\n            quantity = str(item.get('cnt', '')).strip().lower()\n            price = str(item.get('price', '')).strip().lower()\n\n            for line in parsed.get('valid_line', []):\n                words = line.get('words', [])\n                text = ' '.join([w.get('text', '') for w in words]).strip().lower()\n\n                if text in [item_name, quantity, price]:\n                    for w in words:\n                        if 'quad' in w:\n                            for j in range(1, 5):\n                                all_x.append(w['quad'][f'x{j}'])\n                                all_y.append(w['quad'][f'y{j}'])\n\n        # Jika ada koordinat, gabungkan menjadi satu bbox besar\n        if all_x and all_y:\n            merged_quad = {\n                'x1': min(all_x), 'y1': min(all_y),\n                'x2': max(all_x), 'y2': min(all_y),\n                'x3': max(all_x), 'y3': max(all_y),\n                'x4': min(all_x), 'y4': max(all_y),\n            }\n\n            x_c, y_c, w, h = quad_to_yolo(merged_quad, img_w, img_h)\n            yolo_line = f\"{label_map['table']} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\"\n\n            with open(label_path, \"w\") as f:\n                f.write(yolo_line)\n        else:\n            open(label_path, \"w\").close()\n\nsave_yolo_data(train_dataset, \"train\")\nsave_yolo_data(test_dataset, \"train\")\nsave_yolo_data(val_dataset, \"val\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:56:22.964337Z","iopub.execute_input":"2025-06-21T20:56:22.964750Z","iopub.status.idle":"2025-06-21T20:57:17.755027Z","shell.execute_reply.started":"2025-06-21T20:56:22.964734Z","shell.execute_reply":"2025-06-21T20:57:17.754352Z"}},"outputs":[{"name":"stderr","text":"Converting train: 100%|██████████| 800/800 [00:41<00:00, 19.15it/s]\nConverting train: 100%|██████████| 100/100 [00:05<00:00, 18.39it/s]\nConverting val: 100%|██████████| 100/100 [00:05<00:00, 18.62it/s]\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import os\nfrom collections import Counter\n\nlabel_dir = '/kaggle/working/yolo_dataset/labels/train'\nlabel_counts = Counter()\n\nfor label_file in os.listdir(label_dir):\n    if label_file.endswith(\".txt\"):\n        with open(os.path.join(label_dir, label_file), 'r') as f:\n            for line in f:\n                if line.strip():  # skip baris kosong\n                    class_id = int(line.split()[0])\n                    label_counts[class_id] += 1\n\nprint(\"Total label yang ditemukan:\")\nfor cls_id in sorted(label_counts):\n    print(f\"Class {cls_id}: {label_counts[cls_id]} objek\")\n\ntotal = sum(label_counts.values())\nprint(f\"\\n Total semua label: {total}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:17.756240Z","iopub.execute_input":"2025-06-21T20:57:17.756541Z","iopub.status.idle":"2025-06-21T20:57:17.849128Z","shell.execute_reply.started":"2025-06-21T20:57:17.756522Z","shell.execute_reply":"2025-06-21T20:57:17.848516Z"}},"outputs":[{"name":"stdout","text":"Total label yang ditemukan:\nClass 0: 2332 objek\n\n Total semua label: 2332\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"import shutil\nfrom roboflow import Roboflow\n\nrf = Roboflow(api_key=\"QYJz4fQRw4AUwlR6v8Wm\")\nproject_receipt = rf.workspace(\"apple-academy\").project(\"splivu\")\nversion_receipt = project_receipt.version(1)\ndataset_receipt = version_receipt.download(\"yolov8\")\n\nproject_receipt2 = rf.workspace(\"wideai\").project(\"r3c3ipt\")\nversion_receipt2 = project_receipt2.version(6)\ndataset_receipt2 = version_receipt2.download(\"yolov8\")\n\nproject_receipt3 = rf.workspace(\"personal2\").project(\"uhfhlsw-y6nak\")\nversion_receipt3 = project_receipt3.version(1)\ndataset_receipt3 = version_receipt3.download(\"yolov8\")\n                \nproject_receipt4 = rf.workspace(\"testing-gsoi0\").project(\"sds-xusqb\")\nversion_receipt4 = project_receipt4.version(1)\ndataset_receipt4 = version_receipt4.download(\"yolov8\")\n                \n\nprint(\"Dataset: 'invoice'\")\nproject_invoice = rf.workspace(\"helmetproject-vmo6o\").project(\"invoice-pr8ex\")\nversion_invoice = project_invoice.version(1)\ndataset_invoice = version_invoice.download(\"yolov8\")  # -> contoh: /kaggle/working/InvoiceDetection-2\n\nproject_invoice2 = rf.workspace(\"company-inc\").project(\"invoicedetection-jqv45\")\nversion_invoice2 = project_invoice2.version(2)\ndataset_invoice2 = version_invoice2.download(\"yolov8\")\n                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:17.849909Z","iopub.execute_input":"2025-06-21T20:57:17.850198Z","iopub.status.idle":"2025-06-21T20:57:22.490994Z","shell.execute_reply.started":"2025-06-21T20:57:17.850181Z","shell.execute_reply":"2025-06-21T20:57:22.490215Z"}},"outputs":[{"name":"stdout","text":"loading Roboflow workspace...\nloading Roboflow project...\nloading Roboflow workspace...\nloading Roboflow project...\nloading Roboflow workspace...\nloading Roboflow project...\nloading Roboflow workspace...\nloading Roboflow project...\nDataset: 'invoice'\nloading Roboflow workspace...\nloading Roboflow project...\nloading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"**MERGE BBOX AND RELABEL DATASET RECEIPT 2&3**","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport yaml\nfrom PIL import Image\nfrom tqdm import tqdm\n\ndef merge_bboxes(bboxes):\n    x_min = min(b[0] for b in bboxes)\n    y_min = min(b[1] for b in bboxes)\n    x_max = max(b[2] for b in bboxes)\n    y_max = max(b[3] for b in bboxes)\n    return [x_min, y_min, x_max, y_max]\n\n# copy gambar, gabungkan bbox, simpan label baru\ndef process_dataset(dataset_dir, output_dir):\n    data_yaml_path = os.path.join(dataset_dir, \"data.yaml\")\n    with open(data_yaml_path, \"r\") as f:\n        data_yaml_content = yaml.safe_load(f)\n\n    class_id_to_name = {i: name for i, name in enumerate(data_yaml_content['names'])}\n\n    target_labels = [\"Item\", \"Price\", \"Quantity\", \"Sub Price\"]\n\n    for split in ['train', 'valid']:\n        images_dir = os.path.join(dataset_dir, split, \"images\")\n        labels_dir = os.path.join(dataset_dir, split, \"labels\")\n\n        output_images_dir = os.path.join(output_dir, \"images\", split)\n        output_labels_dir = os.path.join(output_dir, \"labels\", split)\n        os.makedirs(output_images_dir, exist_ok=True)\n        os.makedirs(output_labels_dir, exist_ok=True)\n\n        for label_file in tqdm(os.listdir(labels_dir), desc=f\"Processing {split} data\"):\n            if not label_file.endswith(\".txt\"):\n                continue\n\n            label_path = os.path.join(labels_dir, label_file)\n            image_filename = label_file.replace(\".txt\", \".jpg\")\n            image_path = os.path.join(images_dir, image_filename)\n            output_image_path = os.path.join(output_images_dir, image_filename)\n            output_label_path = os.path.join(output_labels_dir, label_file)\n\n            shutil.copy(image_path, output_image_path)\n\n            with open(label_path, \"r\") as f:\n                lines = f.readlines()\n\n            bboxes = []\n            image = Image.open(image_path)\n            img_w, img_h = image.size\n\n            for line in lines:\n                parts = line.strip().split()\n                if len(parts) != 5:\n                    continue\n                class_id = int(parts[0])\n                x_center = float(parts[1])\n                y_center = float(parts[2])\n                width = float(parts[3])\n                height = float(parts[4])\n\n                # Konversi bbox dari format YOLO ke koordinat absolut\n                x_min = (x_center - width / 2) * img_w\n                y_min = (y_center - height / 2) * img_h\n                x_max = (x_center + width / 2) * img_w\n                y_max = (y_center + height / 2) * img_h\n\n                label_name = class_id_to_name.get(class_id, None)\n\n                if label_name in target_labels:\n                    bboxes.append([x_min, y_min, x_max, y_max])\n                # Abaikan label lainnya\n\n            if bboxes:\n                merged_bbox = merge_bboxes(bboxes)\n                # Konversi kembali ke format YOLO (relatif)\n                x_center = ((merged_bbox[0] + merged_bbox[2]) / 2) / img_w\n                y_center = ((merged_bbox[1] + merged_bbox[3]) / 2) / img_h\n                width = (merged_bbox[2] - merged_bbox[0]) / img_w\n                height = (merged_bbox[3] - merged_bbox[1]) / img_h\n\n                with open(output_label_path, \"w\") as f:\n                    f.write(f\"{label_map['table']} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n            else:\n                # tidak ada bbox target = file label kosong\n                open(output_label_path, \"w\").close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:22.492883Z","iopub.execute_input":"2025-06-21T20:57:22.493462Z","iopub.status.idle":"2025-06-21T20:57:22.505074Z","shell.execute_reply.started":"2025-06-21T20:57:22.493443Z","shell.execute_reply":"2025-06-21T20:57:22.504442Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Direktori output\noutput_dir = \"/kaggle/working/yolo_dataset\"\n\n# Proses kedua dataset\nprocess_dataset(\"/kaggle/working/r3c3ipt-6\", output_dir)\nprocess_dataset(\"/kaggle/working/uhfhlsw-1\", output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:22.505763Z","iopub.execute_input":"2025-06-21T20:57:22.505963Z","iopub.status.idle":"2025-06-21T20:57:22.996010Z","shell.execute_reply.started":"2025-06-21T20:57:22.505941Z","shell.execute_reply":"2025-06-21T20:57:22.995255Z"}},"outputs":[{"name":"stderr","text":"Processing train data: 100%|██████████| 312/312 [00:00<00:00, 2166.64it/s]\nProcessing valid data: 100%|██████████| 44/44 [00:00<00:00, 1891.81it/s]\nProcessing train data: 100%|██████████| 399/399 [00:00<00:00, 1414.54it/s]\nProcessing valid data: 100%|██████████| 8/8 [00:00<00:00, 1683.11it/s]\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"label_dir = '/kaggle/working/yolo_dataset/labels/train'\nlabel_counts = Counter()\n\nfor label_file in os.listdir(label_dir):\n    if label_file.endswith(\".txt\"):\n        with open(os.path.join(label_dir, label_file), 'r') as f:\n            for line in f:\n                if line.strip():  # skip baris kosong\n                    class_id = int(line.split()[0])\n                    label_counts[class_id] += 1\n\nprint(\"Total label yang ditemukan:\")\nfor cls_id in sorted(label_counts):\n    print(f\"Class {cls_id}: {label_counts[cls_id]} objek\")\n\ntotal = sum(label_counts.values())\nprint(f\"\\n Total semua label: {total}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:22.996898Z","iopub.execute_input":"2025-06-21T20:57:22.997507Z","iopub.status.idle":"2025-06-21T20:57:23.085634Z","shell.execute_reply.started":"2025-06-21T20:57:22.997488Z","shell.execute_reply":"2025-06-21T20:57:23.084962Z"}},"outputs":[{"name":"stdout","text":"Total label yang ditemukan:\nClass 0: 2332 objek\n\n Total semua label: 2332\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"**MERGE BBOX AND RELABEL DATASET RECEIPT 4**","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport yaml\nfrom PIL import Image\nfrom tqdm import tqdm\n\ndef merge_bboxes(bboxes):\n    x_min = min(b[0] for b in bboxes)\n    y_min = min(b[1] for b in bboxes)\n    x_max = max(b[2] for b in bboxes)\n    y_max = max(b[3] for b in bboxes)\n    return [x_min, y_min, x_max, y_max]\n\ndef process_dataset(dataset_dir, output_dir):\n    data_yaml_path = os.path.join(dataset_dir, \"data.yaml\")\n    with open(data_yaml_path, \"r\") as f:\n        data_yaml_content = yaml.safe_load(f)\n\n    # Mapping class_id ke nama label berdasarkan data.yaml\n    class_id_to_name = {i: name for i, name in enumerate(data_yaml_content['names'])}\n\n    # Label yang ingin digabungkan\n    target_labels = [\n        \"==============================\",\n        \"Roboflow is an end-to-end computer vision platform that helps you\",\n        \"This dataset was exported via roboflow.com on November 24, 2024 at 1:47 AM GMT\", \n        \"r3c3ipt - v6 2023-08-25 10:58am\" \n    ]\n\n    for split in ['train', 'valid']:\n        images_dir = os.path.join(dataset_dir, split, \"images\")\n        labels_dir = os.path.join(dataset_dir, split, \"labels\")\n\n        output_images_dir = os.path.join(output_dir, \"images\", split)\n        output_labels_dir = os.path.join(output_dir, \"labels\", split)\n        os.makedirs(output_images_dir, exist_ok=True)\n        os.makedirs(output_labels_dir, exist_ok=True)\n\n        for label_file in tqdm(os.listdir(labels_dir), desc=f\"Processing {split} data\"):\n            if not label_file.endswith(\".txt\"):\n                continue\n\n            label_path = os.path.join(labels_dir, label_file)\n            image_filename = label_file.replace(\".txt\", \".jpg\")\n            image_path = os.path.join(images_dir, image_filename)\n            output_image_path = os.path.join(output_images_dir, image_filename)\n            output_label_path = os.path.join(output_labels_dir, label_file)\n\n            shutil.copy(image_path, output_image_path)\n\n            with open(label_path, \"r\") as f:\n                lines = f.readlines()\n\n            bboxes = []\n            image = Image.open(image_path)\n            img_w, img_h = image.size\n\n            for line in lines:\n                parts = line.strip().split()\n                if len(parts) != 5:\n                    continue\n                class_id = int(parts[0])\n                x_center = float(parts[1])\n                y_center = float(parts[2])\n                width = float(parts[3])\n                height = float(parts[4])\n\n                # Konversi bbox dari format YOLO ke koordinat absolut\n                x_min = (x_center - width / 2) * img_w\n                y_min = (y_center - height / 2) * img_h\n                x_max = (x_center + width / 2) * img_w\n                y_max = (y_center + height / 2) * img_h\n\n                label_name = class_id_to_name.get(class_id, None)\n\n                if label_name in target_labels:\n                    bboxes.append([x_min, y_min, x_max, y_max])\n\n            if bboxes:\n                merged_bbox = merge_bboxes(bboxes)\n                # Konversi kembali ke format YOLO (relatif)\n                x_center = ((merged_bbox[0] + merged_bbox[2]) / 2) / img_w\n                y_center = ((merged_bbox[1] + merged_bbox[3]) / 2) / img_h\n                width = (merged_bbox[2] - merged_bbox[0]) / img_w\n                height = (merged_bbox[3] - merged_bbox[1]) / img_h\n\n                with open(output_label_path, \"w\") as f:\n                    f.write(f\"{label_map['table']} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n            else:\n                open(output_label_path, \"w\").close()\n\n# Proses dataset\nprocess_dataset(dataset_receipt4.location, output_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:23.086470Z","iopub.execute_input":"2025-06-21T20:57:23.086736Z","iopub.status.idle":"2025-06-21T20:57:23.263396Z","shell.execute_reply.started":"2025-06-21T20:57:23.086715Z","shell.execute_reply":"2025-06-21T20:57:23.262674Z"}},"outputs":[{"name":"stderr","text":"Processing train data: 100%|██████████| 304/304 [00:00<00:00, 2047.91it/s]\nProcessing valid data: 100%|██████████| 16/16 [00:00<00:00, 1814.93it/s]\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"label_dir = '/kaggle/working/yolo_dataset/labels/train'\nlabel_counts = Counter()\n\nfor label_file in os.listdir(label_dir):\n    if label_file.endswith(\".txt\"):\n        with open(os.path.join(label_dir, label_file), 'r') as f:\n            for line in f:\n                if line.strip():  # skip baris kosong\n                    class_id = int(line.split()[0])\n                    label_counts[class_id] += 1\n\nprint(\"Total label yang ditemukan:\")\nfor cls_id in sorted(label_counts):\n    print(f\"Class {cls_id}: {label_counts[cls_id]} objek\")\n\ntotal = sum(label_counts.values())\nprint(f\"\\n Total semua label: {total}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:23.264190Z","iopub.execute_input":"2025-06-21T20:57:23.264552Z","iopub.status.idle":"2025-06-21T20:57:23.354563Z","shell.execute_reply.started":"2025-06-21T20:57:23.264529Z","shell.execute_reply":"2025-06-21T20:57:23.353832Z"}},"outputs":[{"name":"stdout","text":"Total label yang ditemukan:\nClass 0: 2332 objek\n\n Total semua label: 2332\n","output_type":"stream"}],"execution_count":51},{"cell_type":"markdown","source":"**RELABEL OTHER DATASET**","metadata":{}},{"cell_type":"code","source":"import yaml\n\ndef cek_label_names(data_yaml_path):\n    with open(data_yaml_path, 'r') as f:\n        data = yaml.safe_load(f)\n    names = data.get('names', [])\n    print(\"📋 Daftar Label:\")\n    for i, name in enumerate(names):\n        print(f\"  {i}: {name}\")\n    return names\n\ndata_yaml_invoice = os.path.join(dataset_invoice.location, \"data.yaml\")\nlabel_invoice = cek_label_names(data_yaml_invoice)\n\ndata_yaml_invoice2 = os.path.join(dataset_invoice2.location, \"data.yaml\")\nlabel_invoice2 = cek_label_names(data_yaml_invoice2)\n\ndata_yaml_receipt = os.path.join(dataset_receipt.location, \"data.yaml\")\nlabel_receipt = cek_label_names(data_yaml_receipt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:23.355326Z","iopub.execute_input":"2025-06-21T20:57:23.355536Z","iopub.status.idle":"2025-06-21T20:57:23.365196Z","shell.execute_reply.started":"2025-06-21T20:57:23.355522Z","shell.execute_reply":"2025-06-21T20:57:23.364625Z"}},"outputs":[{"name":"stdout","text":"📋 Daftar Label:\n  0: -\n  1: Invoice- NER detection - v1 2024-03-10 8-52am\n📋 Daftar Label:\n  0: CLIENT\n  1: COMPANY\n  2: CUSTOMER\n  3: Customer\n  4: CustomerName\n  5: INVOICE\n  6: PAYMENT\n  7: TABLE\n  8: TOTAL\n📋 Daftar Label:\n  0: receipt\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"def filter_labels_keep_only_class_0(label_dir, keep_class_id=0):\n    kept_files = 0\n    removed_lines = 0\n\n    for file in os.listdir(label_dir):\n        path = os.path.join(label_dir, file)\n        if path.endswith('.txt') and os.path.isfile(path):\n            with open(path, 'r') as f:\n                lines = f.readlines()\n\n            new_lines = [line for line in lines if line.strip().startswith(str(keep_class_id) + ' ')]\n            removed = len(lines) - len(new_lines)\n\n            if new_lines:\n                with open(path, 'w') as f:\n                    f.writelines(new_lines)\n                kept_files += 1\n                removed_lines += removed\n            else:\n                os.remove(path)  # Hapus file jika semua label dihapus\n\n    print(f\"✅ {kept_files} file disimpan dengan hanya label class {keep_class_id}.\")\n    print(f\"🗑️ {removed_lines} baris label lain dibuang.\")\n\nfilter_labels_keep_only_class_0(os.path.join(dataset_receipt.location, 'train', 'labels'))\nfilter_labels_keep_only_class_0(os.path.join(dataset_receipt.location, 'valid', 'labels'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:23.367685Z","iopub.execute_input":"2025-06-21T20:57:23.368115Z","iopub.status.idle":"2025-06-21T20:57:23.394315Z","shell.execute_reply.started":"2025-06-21T20:57:23.368093Z","shell.execute_reply":"2025-06-21T20:57:23.393605Z"}},"outputs":[{"name":"stdout","text":"✅ 146 file disimpan dengan hanya label class 0.\n🗑️ 0 baris label lain dibuang.\n✅ 15 file disimpan dengan hanya label class 0.\n🗑️ 0 baris label lain dibuang.\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"# Dataset InvoiceDetection hanya pakai label \"-\"\nfilter_labels_keep_only_class_0(os.path.join(dataset_invoice.location, 'train', 'labels'))\nfilter_labels_keep_only_class_0(os.path.join(dataset_invoice.location, 'valid', 'labels'))\nfilter_labels_keep_only_class_0(os.path.join(dataset_invoice2.location, 'train', 'labels'), 7)\nfilter_labels_keep_only_class_0(os.path.join(dataset_invoice2.location, 'valid', 'labels'), 7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:23.394903Z","iopub.execute_input":"2025-06-21T20:57:23.395082Z","iopub.status.idle":"2025-06-21T20:57:23.487777Z","shell.execute_reply.started":"2025-06-21T20:57:23.395068Z","shell.execute_reply":"2025-06-21T20:57:23.487116Z"}},"outputs":[{"name":"stdout","text":"✅ 693 file disimpan dengan hanya label class 0.\n🗑️ 0 baris label lain dibuang.\n✅ 65 file disimpan dengan hanya label class 0.\n🗑️ 0 baris label lain dibuang.\n✅ 0 file disimpan dengan hanya label class 7.\n🗑️ 0 baris label lain dibuang.\n✅ 0 file disimpan dengan hanya label class 7.\n🗑️ 0 baris label lain dibuang.\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"def relabel_class_0_to_target(label_dir, new_class_id=0):\n    for file in os.listdir(label_dir):\n        path = os.path.join(label_dir, file)\n        if path.endswith('.txt') and os.path.isfile(path):\n            with open(path, 'r') as f:\n                lines = f.readlines()\n\n            new_lines = []\n            for line in lines:\n                parts = line.strip().split()\n                if parts[0] == '0':\n                    parts[0] = str(new_class_id)\n                    new_lines.append(' '.join(parts))\n\n            with open(path, 'w') as f:\n                f.write('\\n'.join(new_lines))\n\nrelabel_class_0_to_target(os.path.join(dataset_receipt.location, 'train', 'labels'), 0)\nrelabel_class_0_to_target(os.path.join(dataset_receipt.location, 'valid', 'labels'), 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:23.488460Z","iopub.execute_input":"2025-06-21T20:57:23.488775Z","iopub.status.idle":"2025-06-21T20:57:23.514114Z","shell.execute_reply.started":"2025-06-21T20:57:23.488758Z","shell.execute_reply":"2025-06-21T20:57:23.513441Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"relabel_class_0_to_target(os.path.join(dataset_invoice.location, 'train', 'labels'), 0)\nrelabel_class_0_to_target(os.path.join(dataset_invoice.location, 'valid', 'labels'), 0)\nrelabel_class_0_to_target(os.path.join(dataset_invoice2.location, 'train', 'labels'), 0)\nrelabel_class_0_to_target(os.path.join(dataset_invoice2.location, 'valid', 'labels'), 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:23.514774Z","iopub.execute_input":"2025-06-21T20:57:23.514967Z","iopub.status.idle":"2025-06-21T20:57:23.604942Z","shell.execute_reply.started":"2025-06-21T20:57:23.514953Z","shell.execute_reply":"2025-06-21T20:57:23.604438Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# Initialize overall counters for each dataset type\ntotal_receipt_labels = Counter()\ntotal_invoice1_labels = Counter()\ntotal_invoice2_labels = Counter()\n\nprint(\"Mulai menggabungkan dataset dan menghitung label...\")\n\nfor split in ['train', 'valid']:\n    # Initialize split-specific counters for each dataset type\n    split_receipt_labels = Counter()\n    split_invoice1_labels = Counter()\n    split_invoice2_labels = Counter()\n\n    for subfolder in ['images', 'labels']:\n        src1 = os.path.join(dataset_receipt.location, split, subfolder)\n        src2 = os.path.join(dataset_invoice.location, split, subfolder)\n        src3 = os.path.join(dataset_invoice2.location, split, subfolder)\n        dst = os.path.join(base_dir, subfolder, split)\n\n        os.makedirs(dst, exist_ok=True)\n\n        for i, src in enumerate([src1, src2, src3], start=1):\n            if os.path.exists(src):\n                files = [f for f in os.listdir(src) if os.path.isfile(os.path.join(src, f))]\n                print(f\"Menyalin {len(files)} file dari sumber {i} ({split}/{subfolder})\")\n\n                for f in files:\n                    shutil.copy(os.path.join(src, f), os.path.join(dst, f))\n\n                    # If it's a labels subfolder and a .txt file, count the labels\n                    if subfolder == 'labels' and f.endswith(\".txt\"):\n                        label_file_path = os.path.join(src, f)\n                        with open(label_file_path, 'r') as label_f:\n                            for line in label_f:\n                                if line.strip():  # Skip empty lines\n                                    class_id = int(line.split()[0])\n                                    if i == 1: # dataset_receipt\n                                        split_receipt_labels[class_id] += 1\n                                        total_receipt_labels[class_id] += 1\n                                    elif i == 2: # dataset_invoice (invoice 1)\n                                        split_invoice1_labels[class_id] += 1\n                                        total_invoice1_labels[class_id] += 1\n                                    elif i == 3: # dataset_invoice2 (invoice 2)\n                                        split_invoice2_labels[class_id] += 1\n                                        total_invoice2_labels[class_id] += 1\n            else:\n                print(f\"Folder tidak ditemukan: {src}\")\n\n    # Print label counts for the current split\n    print(\"\\n---\")\n    print(f\"Jumlah Label per Class untuk Split '{split}':\")\n    print(\"Dataset Receipt:\")\n    if split_receipt_labels:\n        for cls_id in sorted(split_receipt_labels):\n            print(f\"  Class {cls_id}: {split_receipt_labels[cls_id]} objek\")\n    else:\n        print(\"  Tidak ada label ditemukan.\")\n\n    print(\"\\nDataset Invoice 1:\")\n    if split_invoice1_labels:\n        for cls_id in sorted(split_invoice1_labels):\n            print(f\"  Class {cls_id}: {split_invoice1_labels[cls_id]} objek\")\n    else:\n        print(\"  Tidak ada label ditemukan.\")\n\n    print(\"\\nDataset Invoice 2:\")\n    if split_invoice2_labels:\n        for cls_id in sorted(split_invoice2_labels):\n            print(f\"  Class {cls_id}: {split_invoice2_labels[cls_id]} objek\")\n    else:\n        print(\"  Tidak ada label ditemukan.\")\n    print(\"---\")\n\n\nprint(\"\\nSelesai menggabungkan dataset dan menghitung label.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:23.605628Z","iopub.execute_input":"2025-06-21T20:57:23.605842Z","iopub.status.idle":"2025-06-21T20:57:24.629610Z","shell.execute_reply.started":"2025-06-21T20:57:23.605818Z","shell.execute_reply":"2025-06-21T20:57:24.628985Z"}},"outputs":[{"name":"stdout","text":"Mulai menggabungkan dataset dan menghitung label...\nMenyalin 146 file dari sumber 1 (train/images)\nMenyalin 774 file dari sumber 2 (train/images)\nMenyalin 5310 file dari sumber 3 (train/images)\nMenyalin 146 file dari sumber 1 (train/labels)\nMenyalin 693 file dari sumber 2 (train/labels)\nMenyalin 0 file dari sumber 3 (train/labels)\n\n---\nJumlah Label per Class untuk Split 'train':\nDataset Receipt:\n  Class 0: 146 objek\n\nDataset Invoice 1:\n  Class 0: 717 objek\n\nDataset Invoice 2:\n  Tidak ada label ditemukan.\n---\nMenyalin 15 file dari sumber 1 (valid/images)\nMenyalin 73 file dari sumber 2 (valid/images)\nMenyalin 324 file dari sumber 3 (valid/images)\nMenyalin 15 file dari sumber 1 (valid/labels)\nMenyalin 65 file dari sumber 2 (valid/labels)\nMenyalin 0 file dari sumber 3 (valid/labels)\n\n---\nJumlah Label per Class untuk Split 'valid':\nDataset Receipt:\n  Class 0: 15 objek\n\nDataset Invoice 1:\n  Class 0: 71 objek\n\nDataset Invoice 2:\n  Tidak ada label ditemukan.\n---\n\nSelesai menggabungkan dataset dan menghitung label.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import yaml\nimport os\n\ndataset_yaml = {\n    'path': '/kaggle/working/yolo_dataset',\n    'train': 'images/train',\n    'val': 'images/val',\n    'nc': 2,\n    'names': {\n        0: 'table',\n        1: 'not_table'\n    }\n}\n\nos.makedirs('/kaggle/working/yolo_dataset', exist_ok=True)\n\n# Simpan dataset.yaml\nwith open('/kaggle/working/yolo_dataset/dataset.yaml', 'w') as f:\n    yaml.dump(dataset_yaml, f, sort_keys=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:24.630390Z","iopub.execute_input":"2025-06-21T20:57:24.630685Z","iopub.status.idle":"2025-06-21T20:57:24.636420Z","shell.execute_reply.started":"2025-06-21T20:57:24.630661Z","shell.execute_reply":"2025-06-21T20:57:24.635670Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"label_dir = '/kaggle/working/yolo_dataset/labels/train' \nlabel_counts = Counter()\n\nfor label_file in os.listdir(label_dir):\n    if label_file.endswith(\".txt\"):\n        with open(os.path.join(label_dir, label_file), 'r') as f:\n            for line in f:\n                if line.strip():  # skip baris kosong\n                    class_id = int(line.split()[0])\n                    label_counts[class_id] += 1\n\nprint(\"Total label yang ditemukan:\")\nfor cls_id in sorted(label_counts):\n    print(f\"Class {cls_id}: {label_counts[cls_id]} objek\")\n\ntotal = sum(label_counts.values())\nprint(f\"\\nTotal semua label: {total}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:24.637078Z","iopub.execute_input":"2025-06-21T20:57:24.637325Z","iopub.status.idle":"2025-06-21T20:57:24.736271Z","shell.execute_reply.started":"2025-06-21T20:57:24.637300Z","shell.execute_reply":"2025-06-21T20:57:24.735739Z"}},"outputs":[{"name":"stdout","text":"Total label yang ditemukan:\nClass 0: 2335 objek\n\nTotal semua label: 2335\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"img_dir = '/kaggle/working/yolo_dataset/images/train'\nlabel_dir = '/kaggle/working/yolo_dataset/labels/train'\n\nimg_names = set(f.rsplit('.', 1)[0] for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png')))\nlabel_names = set(f.rsplit('.', 1)[0] for f in os.listdir(label_dir) if f.endswith('.txt'))\n\nmissing_labels = img_names - label_names\nprint(f\"[1] Menghapus {len(missing_labels)} gambar tanpa label...\")\n\nfor name in missing_labels:\n    for ext in ['.jpg', '.png']:\n        img_path = os.path.join(img_dir, name + ext)\n        if os.path.exists(img_path):\n            os.remove(img_path)\n\nsegment_files = []\n\nfor label_file in os.listdir(label_dir):\n    if label_file.endswith(\".txt\"):\n        with open(os.path.join(label_dir, label_file), 'r') as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) > 5:\n                    segment_files.append(label_file)\n                    break  # cukup satu baris untuk tahu ini segmentasi\n\nprint(f\"[2] Menghapus {len(segment_files)} gambar & label dengan segmentasi...\")\n\nfor f in segment_files:\n    name = f.rsplit('.', 1)[0]\n    \n    # Hapus label\n    label_path = os.path.join(label_dir, f)\n    if os.path.exists(label_path):\n        os.remove(label_path)\n    \n    # Hapus gambar pasangannya (kalau ada)\n    for ext in ['.jpg', '.png']:\n        img_path = os.path.join(img_dir, name + ext)\n        if os.path.exists(img_path):\n            os.remove(img_path)\n\nprint(\"\\nSelesai membersihkan dataset.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:24.736995Z","iopub.execute_input":"2025-06-21T20:57:24.737242Z","iopub.status.idle":"2025-06-21T20:57:24.982491Z","shell.execute_reply.started":"2025-06-21T20:57:24.737222Z","shell.execute_reply":"2025-06-21T20:57:24.981893Z"}},"outputs":[{"name":"stdout","text":"[1] Menghapus 4415 gambar tanpa label...\n[2] Menghapus 3 gambar & label dengan segmentasi...\n\nSelesai membersihkan dataset.\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"img_dir = '/kaggle/working/yolo_dataset/images/train'\nlabel_dir = '/kaggle/working/yolo_dataset/labels/train'\n\nimg_files = set(f.rsplit('.', 1)[0] for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png')))\nlabel_files = set(f.rsplit('.', 1)[0] for f in os.listdir(label_dir) if f.endswith('.txt'))\n\nmissing_labels = img_files - label_files\nprint(f\"{len(missing_labels)} gambar tidak memiliki label.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:24.983129Z","iopub.execute_input":"2025-06-21T20:57:24.983338Z","iopub.status.idle":"2025-06-21T20:57:24.997072Z","shell.execute_reply.started":"2025-06-21T20:57:24.983320Z","shell.execute_reply":"2025-06-21T20:57:24.996470Z"}},"outputs":[{"name":"stdout","text":"0 gambar tidak memiliki label.\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"import os\n\nlabel_dir = '/kaggle/working/yolo_dataset/labels/train'\nsegment_files = []\n\nfor label_file in os.listdir(label_dir):\n    if label_file.endswith(\".txt\"):\n        with open(os.path.join(label_dir, label_file), 'r') as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) > 5:\n                    segment_files.append(label_file)\n                    break  # cukup satu baris aja untuk memastikan file ini segmentasi\n\nprint(f\"Jumlah file label yang mengandung segmentasi: {len(segment_files)}\")\nprint(\"Contoh file segmentasi:\", segment_files)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:24.997868Z","iopub.execute_input":"2025-06-21T20:57:24.998126Z","iopub.status.idle":"2025-06-21T20:57:25.082616Z","shell.execute_reply.started":"2025-06-21T20:57:24.998104Z","shell.execute_reply":"2025-06-21T20:57:25.081900Z"}},"outputs":[{"name":"stdout","text":"Jumlah file label yang mengandung segmentasi: 0\nContoh file segmentasi: []\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"label_dir = '/kaggle/working/yolo_dataset/labels/train'\nobj_count_per_image = []\n\nfor file in os.listdir(label_dir):\n    if file.endswith('.txt'):\n        with open(os.path.join(label_dir, file), 'r') as f:\n            lines = [line for line in f if line.strip()]\n            obj_count_per_image.append(len(lines))\n\ncounter = Counter(obj_count_per_image)\n\nprint(\"Distribusi jumlah objek class 0 per gambar:\")\nfor k in sorted(counter):\n    print(f\"{k} objek: {counter[k]} gambar\")\n\nprint(f\"\\nTotal gambar dengan objek: {len(obj_count_per_image)}\")\nprint(f\"Total objek class 0: {sum(obj_count_per_image)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:25.083276Z","iopub.execute_input":"2025-06-21T20:57:25.083518Z","iopub.status.idle":"2025-06-21T20:57:25.166756Z","shell.execute_reply.started":"2025-06-21T20:57:25.083504Z","shell.execute_reply":"2025-06-21T20:57:25.166229Z"}},"outputs":[{"name":"stdout","text":"Distribusi jumlah objek class 0 per gambar:\n0 objek: 1319 gambar\n1 objek: 2287 gambar\n2 objek: 18 gambar\n3 objek: 3 gambar\n\nTotal gambar dengan objek: 3627\nTotal objek class 0: 2332\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"from ultralytics import YOLO\nmodel = YOLO('yolov8n.pt')\n\nresults = model.train(\n    data = '/kaggle/working/yolo_dataset/dataset.yaml',\n    batch = 24,\n    epochs = 35,\n    device = 0,\n    lr0 = 3e-4,\n    optimizer='AdamW',\n    imgsz = 640,\n    save_period = 10\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:57:25.167566Z","iopub.execute_input":"2025-06-21T20:57:25.167804Z","iopub.status.idle":"2025-06-21T21:18:50.712646Z","shell.execute_reply.started":"2025-06-21T20:57:25.167781Z","shell.execute_reply":"2025-06-21T21:18:50.711882Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.158 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=24, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/yolo_dataset/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=35, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0003, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train3, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \nModel summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1681.8±854.0 MB/s, size: 85.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/train.cache... 3627 images, 1319 backgrounds, 0 corrupt: 100%|██████████| 3627/3627 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 445.2±121.6 MB/s, size: 209.4 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/val.cache... 100 images, 46 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0003, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005625000000000001), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train3\u001b[0m\nStarting training for 35 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/35      5.75G      1.417       2.35      1.387          2        640: 100%|██████████| 152/152 [00:37<00:00,  4.02it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.19it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.528       0.56      0.669      0.398\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/35      5.75G      1.145      1.503      1.203          4        640: 100%|██████████| 152/152 [00:36<00:00,  4.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.02it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.606      0.667      0.661       0.45\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/35      5.75G      1.091      1.317       1.18          3        640: 100%|██████████| 152/152 [00:35<00:00,  4.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.60it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.842       0.79      0.846      0.677\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/35      5.75G      1.033      1.195      1.146          4        640: 100%|██████████| 152/152 [00:35<00:00,  4.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.865      0.778      0.871      0.655\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/35      5.75G     0.9948      1.128      1.117          3        640: 100%|██████████| 152/152 [00:35<00:00,  4.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.806      0.846      0.856       0.68\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/35      5.75G     0.9491      1.026      1.098          5        640: 100%|██████████| 152/152 [00:35<00:00,  4.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.50it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54       0.94      0.815      0.945      0.754\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/35      5.75G     0.9211     0.9873       1.09          3        640: 100%|██████████| 152/152 [00:35<00:00,  4.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.909      0.833      0.919       0.77\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/35      5.75G     0.9064     0.9723      1.077          5        640: 100%|██████████| 152/152 [00:35<00:00,  4.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.57it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.916      0.804       0.91      0.723\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/35      5.75G     0.8736      0.915      1.056          6        640: 100%|██████████| 152/152 [00:35<00:00,  4.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.53it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.822      0.963      0.945      0.763\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/35      5.75G     0.8542     0.8833      1.051          1        640: 100%|██████████| 152/152 [00:35<00:00,  4.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.13it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54       0.85      0.942      0.951      0.788\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      11/35      5.75G      0.841     0.8463      1.038          3        640: 100%|██████████| 152/152 [00:35<00:00,  4.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.814      0.973      0.947      0.787\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      12/35      5.75G     0.8302     0.8331       1.04          3        640: 100%|██████████| 152/152 [00:35<00:00,  4.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.872      0.944      0.953      0.797\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      13/35      5.75G     0.8102     0.8182      1.028          5        640: 100%|██████████| 152/152 [00:35<00:00,  4.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.45it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.891      0.905       0.96      0.798\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      14/35      5.75G     0.7869     0.8036      1.018          3        640: 100%|██████████| 152/152 [00:35<00:00,  4.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.31it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54       0.86      0.926      0.964      0.805\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      15/35      5.75G     0.8036     0.7972      1.027          5        640: 100%|██████████| 152/152 [00:35<00:00,  4.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.852      0.981      0.952      0.821\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      16/35      5.75G     0.7669     0.7604      1.015          2        640: 100%|██████████| 152/152 [00:35<00:00,  4.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.32it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.854      0.944      0.966      0.826\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      17/35      5.75G     0.7462     0.7477      1.006          5        640: 100%|██████████| 152/152 [00:35<00:00,  4.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.72it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.878      0.929      0.944      0.813\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      18/35      5.75G     0.7564      0.723      1.003          6        640: 100%|██████████| 152/152 [00:35<00:00,  4.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.77it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.909      0.923      0.951      0.813\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      19/35      5.75G     0.7361     0.7811     0.9993          0        640: 100%|██████████| 152/152 [00:35<00:00,  4.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.73it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.879      0.926      0.952      0.806\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      20/35      5.75G     0.7308     0.7156     0.9961          4        640: 100%|██████████| 152/152 [00:35<00:00,  4.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.882      0.969      0.972      0.829\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      21/35      5.75G     0.7215     0.7012     0.9892          5        640: 100%|██████████| 152/152 [00:35<00:00,  4.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.52it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.925      0.963      0.975      0.842\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      22/35      5.75G     0.7026     0.6986     0.9849          3        640: 100%|██████████| 152/152 [00:35<00:00,  4.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.17it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.996      0.907      0.985       0.83\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      23/35      5.75G     0.7026      0.675     0.9909          5        640: 100%|██████████| 152/152 [00:35<00:00,  4.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.885      0.944      0.966      0.841\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      24/35      5.75G     0.6664     0.6568     0.9715          4        640: 100%|██████████| 152/152 [00:35<00:00,  4.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54       0.93      0.977      0.982      0.858\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      25/35      5.75G     0.6766     0.6611     0.9785          3        640: 100%|██████████| 152/152 [00:35<00:00,  4.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.96it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.981      0.976      0.989      0.856\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Closing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      26/35      5.75G     0.6198     0.6046     0.9683          1        640: 100%|██████████| 152/152 [00:36<00:00,  4.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.96it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.994      0.963      0.992      0.874\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      27/35      5.75G     0.6016     0.5721      0.946          2        640: 100%|██████████| 152/152 [00:35<00:00,  4.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.78it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.916      0.926       0.98      0.848\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      28/35      5.75G     0.5863      0.561     0.9487          2        640: 100%|██████████| 152/152 [00:34<00:00,  4.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.06it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.959      0.944      0.986      0.871\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      29/35      5.75G     0.5624     0.5446     0.9301          1        640: 100%|██████████| 152/152 [00:35<00:00,  4.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.966      0.907      0.984      0.864\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      30/35      5.75G     0.5433     0.5336     0.9336          2        640: 100%|██████████| 152/152 [00:34<00:00,  4.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.965      0.926      0.985      0.877\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      31/35      5.75G     0.5364     0.5269     0.9236          3        640: 100%|██████████| 152/152 [00:34<00:00,  4.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.08it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.912      0.963      0.982      0.874\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      32/35      5.75G     0.5246      0.523     0.9158          1        640: 100%|██████████| 152/152 [00:34<00:00,  4.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.66it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.981      0.938      0.987      0.887\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      33/35      5.75G     0.5115     0.5214     0.9065          0        640: 100%|██████████| 152/152 [00:34<00:00,  4.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.53it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54       0.93      0.979      0.986      0.876\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      34/35      5.75G     0.5134     0.5039     0.9097          2        640: 100%|██████████| 152/152 [00:34<00:00,  4.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.47it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.978      0.926      0.988      0.889\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      35/35      5.75G     0.4962      0.495     0.9041          2        640: 100%|██████████| 152/152 [00:34<00:00,  4.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.12it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.988      0.926      0.988      0.893\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n35 epochs completed in 0.353 hours.\nOptimizer stripped from runs/detect/train3/weights/last.pt, 6.2MB\nOptimizer stripped from runs/detect/train3/weights/best.pt, 6.2MB\n\nValidating runs/detect/train3/weights/best.pt...\nUltralytics 8.3.158 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\nModel summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.30it/s]\ninvalid value encountered in less\ninvalid value encountered in less\n","output_type":"stream"},{"name":"stdout","text":"                   all        100         54      0.988      0.926      0.988      0.891\n                 table         54         54      0.988      0.926      0.988      0.891\nSpeed: 0.1ms preprocess, 2.0ms inference, 0.0ms loss, 1.8ms postprocess per image\nResults saved to \u001b[1mruns/detect/train3\u001b[0m\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"import shutil\n\n# Path folder yang ingin dikompres (misalnya hasil training YOLOv8)\nfolder_path = \"/kaggle/working/runs/detect/train\"\nzip_path = \"/kaggle/working/train_results.zip\"\n\n# Buat zip dari folder\nshutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', folder_path)\n\nprint(\"Folder berhasil dikompres ke:\", zip_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T21:18:50.714080Z","iopub.execute_input":"2025-06-21T21:18:50.714378Z","iopub.status.idle":"2025-06-21T21:18:50.780305Z","shell.execute_reply.started":"2025-06-21T21:18:50.714342Z","shell.execute_reply":"2025-06-21T21:18:50.779734Z"}},"outputs":[{"name":"stdout","text":"Folder berhasil dikompres ke: /kaggle/working/train_results.zip\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"from PIL import Image\nfrom IPython.display import display\n\nimg = Image.open(\"/kaggle/working/runs/detect/train/results.png\")\ndisplay(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T21:18:50.820891Z","iopub.status.idle":"2025-06-21T21:18:50.821184Z","shell.execute_reply.started":"2025-06-21T21:18:50.821054Z","shell.execute_reply":"2025-06-21T21:18:50.821070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO(\"/kaggle/working/runs/detect/train/weights/best.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T21:18:50.822279Z","iopub.status.idle":"2025-06-21T21:18:50.822563Z","shell.execute_reply.started":"2025-06-21T21:18:50.822445Z","shell.execute_reply":"2025-06-21T21:18:50.822458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\ndataset = load_dataset(\"naver-clova-ix/cord-v2\", split=\"train\")\n# image_path = dataset[12]['image']  # Sudah dalam bentuk PIL.Image\nimage_path = Image.open(\"/kaggle/input/contoh/contoh-1.jpeg\")\nimage_np = cv2.cvtColor(np.array(image_path), cv2.COLOR_RGB2BGR)\nimage_resized = cv2.resize(image_np, (600, 600))\n\nresults = model(image_resized)  # Ganti dengan path gambar kamu\n\n\n# Tampilkan hasilnya\nresults[0].show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T21:18:50.823776Z","iopub.status.idle":"2025-06-21T21:18:50.824015Z","shell.execute_reply.started":"2025-06-21T21:18:50.823899Z","shell.execute_reply":"2025-06-21T21:18:50.823909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for result in results:\n    boxes = result.boxes  # bounding boxes\n    probs = result.probs  # klasifikasi probabilitas (jika ada)\n    print(boxes.xyxy)     # koordinat [x1, y1, x2, y2]\n    print(boxes.conf)     # confidence score\n    print(boxes.cls)      # class index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T21:18:50.824908Z","iopub.status.idle":"2025-06-21T21:18:50.825259Z","shell.execute_reply.started":"2025-06-21T21:18:50.825078Z","shell.execute_reply":"2025-06-21T21:18:50.825091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for box in results[0].boxes:\n    print(box.xyxy, box.conf, box.cls)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T21:18:50.826385Z","iopub.status.idle":"2025-06-21T21:18:50.826703Z","shell.execute_reply.started":"2025-06-21T21:18:50.826543Z","shell.execute_reply":"2025-06-21T21:18:50.826557Z"}},"outputs":[],"execution_count":null}]}
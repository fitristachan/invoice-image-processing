{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11896840,"sourceType":"datasetVersion","datasetId":7478273},{"sourceId":11897091,"sourceType":"datasetVersion","datasetId":7478450},{"sourceId":11899363,"sourceType":"datasetVersion","datasetId":7479204},{"sourceId":406134,"sourceType":"modelInstanceVersion","modelInstanceId":331874,"modelId":352758}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pillow\n!pip install lmdb opencv-python-headless imgaug --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T06:12:24.112931Z","iopub.execute_input":"2025-05-22T06:12:24.113422Z","iopub.status.idle":"2025-05-22T06:12:31.798899Z","shell.execute_reply.started":"2025-05-22T06:12:24.113396Z","shell.execute_reply":"2025-05-22T06:12:31.798219Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport cv2\nimport lmdb\nimport random\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom PIL import Image, ImageDraw, ImageFont\nimport io\nimport pickle\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T06:13:43.791328Z","iopub.execute_input":"2025-05-22T06:13:43.791929Z","iopub.status.idle":"2025-05-22T06:13:43.795820Z","shell.execute_reply.started":"2025-05-22T06:13:43.791900Z","shell.execute_reply":"2025-05-22T06:13:43.795044Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Font size typical receipt text, bisa di-tweak\nFONT_SIZE = 28\nPADDING = 10  # pixel padding di sekitar text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T06:13:49.926783Z","iopub.execute_input":"2025-05-22T06:13:49.927172Z","iopub.status.idle":"2025-05-22T06:13:49.931167Z","shell.execute_reply.started":"2025-05-22T06:13:49.927140Z","shell.execute_reply":"2025-05-22T06:13:49.930501Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nimport random\nfrom tqdm.auto import tqdm\nfrom PIL import Image, ImageDraw, ImageFont\nimport numpy as np\n\n\n# Font folder dan list fonts\nfont_dir = \"/kaggle/input/receipt-fonts/fonts\"\nreceipt_fonts = [\n    os.path.join(font_dir, f)\n    for f in os.listdir(font_dir)\n    if f.lower().endswith((\".ttf\", \".otf\"))\n]\n\noutput_base_dir = \"/kaggle/working/generated_receipt_images\"\nos.makedirs(output_base_dir, exist_ok=True)\n\ndef generate_image(text, font_path, font_size=FONT_SIZE):\n    font = ImageFont.truetype(font_path, font_size)\n    \n    dummy_img = Image.new(\"RGB\", (1, 1))\n    draw = ImageDraw.Draw(dummy_img)\n    bbox = draw.textbbox((0, 0), text, font=font)\n    text_width = bbox[2] - bbox[0]\n    text_height = bbox[3] - bbox[1]\n\n    img_width = text_width + 2 * PADDING\n    img_height = text_height + 2 * PADDING\n    image = Image.new(\"RGB\", (img_width, img_height), color=\"white\")\n\n    draw = ImageDraw.Draw(image)\n    draw.text((PADDING, PADDING), text, font=font, fill=\"black\")\n\n    return image\n\ndef generate_images_per_font(font_path, all_texts, num_images=500):\n    font_name = os.path.splitext(os.path.basename(font_path))[0]\n    font_output_dir = os.path.join(output_base_dir, font_name)\n    os.makedirs(font_output_dir, exist_ok=True)\n\n    image_count = 0\n    for i in tqdm(range(num_images), desc=f\"Generating images for {font_name}\"):\n        text = random.choice(all_texts)\n        img = generate_image(text, font_path, FONT_SIZE)\n        img.save(os.path.join(font_output_dir, f\"{font_name}_{i:04d}.png\"))\n        image_count += 1\n\n    print(f\"‚úÖ Done! Total images generated: {image_count}\")\n    print(f\"üìÅ Output per font: saved under {font_output_dir}/\")\n\nprint(f\"Total fonts found: {len(receipt_fonts)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T06:13:54.514535Z","iopub.execute_input":"2025-05-22T06:13:54.515097Z","iopub.status.idle":"2025-05-22T06:13:54.542069Z","shell.execute_reply.started":"2025-05-22T06:13:54.515076Z","shell.execute_reply":"2025-05-22T06:13:54.541386Z"}},"outputs":[{"name":"stdout","text":"Total fonts found: 7\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nfrom tqdm import tqdm\n\n# === Step 1: Load Data ===\ndf = pd.read_csv(\"/kaggle/input/openfoodfacts-export-csv/openfoodfacts_export_csv.csv\", \n                 on_bad_lines='skip', sep='\\t', low_memory=True)\n\ndf = df[[\"product_name_nb\", \"generic_name_nb\", \"brands\"]]\nall_words = df.to_numpy().flatten()\n\n# Filter NaN dan duplikat\nall_words = [x for x in all_words if str(x) != 'nan']\nall_words = list(set(all_words))\n\n# === Step 2: Generate Price Strings ===\nnumber_strings = []\nfor _ in range(len(all_words) * 9 // 10):\n    digits = np.random.randint(1, 100, 4)\n    number_strings.append(f\"{digits[0]},{str(digits[1]).zfill(2)}\")\n\nfor _ in range(len(all_words) * 1 // 10):\n    before = np.random.randint(100, 999)\n    after = str(np.random.randint(1, 99)).zfill(2)\n    number_strings.append(f\"{before},{after}\")\n\n# === Step 3: Combine Text + Price + Label ===\nall_combinations = []\n\nfor idx, word in enumerate(tqdm(all_words[:1000])):  # cukup 1000 kata\n    for price in random.sample(number_strings, 5):\n        combined_string = f\"{word}    {price}\"\n        \n        # Dummy image path (nanti bisa diganti saat generate gambar)\n        image_path = f\"images/{idx}_{word.replace(' ', '_')}.jpg\"\n        \n        # Dummy quad bbox (contoh: kiri atas, kanan atas, kanan bawah, kiri bawah)\n        bbox = [[0, 0], [100, 0], [100, 30], [0, 30]]  # Ukuran bisa disesuaikan\n        \n        # Format label line\n        label_line = f\"{image_path}\\t{combined_string}\\t{bbox}\"\n        all_combinations.append(label_line)\n\n# === Step 4: Simpan ke label.txt ===\nwith open(\"label.txt\", \"w\", encoding=\"utf-8\") as f:\n    for line in all_combinations:\n        f.write(line + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T06:13:59.684375Z","iopub.execute_input":"2025-05-22T06:13:59.684640Z","iopub.status.idle":"2025-05-22T06:14:00.335128Z","shell.execute_reply.started":"2025-05-22T06:13:59.684620Z","shell.execute_reply":"2025-05-22T06:14:00.334373Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1535496718.py:7: DtypeWarning: Columns (0,1,3,4,5,6,7,10,13,16,18,19,21,24,27,28,29,30,32,33,34,35,36,37,38,39,40,41,43,44,45,46,47,48,50,51,53,54,55,56,58,65,79,80,81,82,83,85,86,87,92,93,94,95,96,99,102,105,106,108,109,110,113,115,116,117,118,119,121,122,123,124,159,175,183,187,191,193,195,197,199,201,203,205,207,211,213,215,217,221,223,225,229,231,235,239,243,247,251,255,259,263,267,273,277,281,285,287,289,293,297,301,305,309,313,317,321,323,325,329,333,335,341,347,349,351,353,355,357,359,361,363,365,367,369,401,402,403,405,406,407,408,425,426,427,429,430,433,434,435,436,437,438) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"/kaggle/input/openfoodfacts-export-csv/openfoodfacts_export_csv.csv\",\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 65347.11it/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"total_images_generated = 0\nfor font_path in receipt_fonts:\n    generate_images_per_font(font_path, all_combinations, num_images=500)\n    total_images_generated += 500\n\nprint(f\"üéâ All fonts processed!\")\nprint(f\"üìä Total images generated overall: {total_images_generated}\")\nprint(f\"üìÅ Output base directory: {output_base_dir}/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T06:14:05.000707Z","iopub.execute_input":"2025-05-22T06:14:05.001015Z","iopub.status.idle":"2025-05-22T06:14:55.957419Z","shell.execute_reply.started":"2025-05-22T06:14:05.000973Z","shell.execute_reply":"2025-05-22T06:14:55.956746Z"}},"outputs":[{"name":"stderr","text":"Generating images for Monaco: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:05<00:00, 87.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Done! Total images generated: 500\nüìÅ Output per font: saved under /kaggle/working/generated_receipt_images/Monaco/\n","output_type":"stream"},{"name":"stderr","text":"Generating images for MerchantCopyDoublesize-jE7R: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:12<00:00, 39.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Done! Total images generated: 500\nüìÅ Output per font: saved under /kaggle/working/generated_receipt_images/MerchantCopyDoublesize-jE7R/\n","output_type":"stream"},{"name":"stderr","text":"Generating images for DejaVuSans: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:04<00:00, 123.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Done! Total images generated: 500\nüìÅ Output per font: saved under /kaggle/working/generated_receipt_images/DejaVuSans/\n","output_type":"stream"},{"name":"stderr","text":"Generating images for MerchantCopy-GOXq: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:07<00:00, 63.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Done! Total images generated: 500\nüìÅ Output per font: saved under /kaggle/working/generated_receipt_images/MerchantCopy-GOXq/\n","output_type":"stream"},{"name":"stderr","text":"Generating images for MerchantCopyWide-z8m0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:11<00:00, 44.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Done! Total images generated: 500\nüìÅ Output per font: saved under /kaggle/working/generated_receipt_images/MerchantCopyWide-z8m0/\n","output_type":"stream"},{"name":"stderr","text":"Generating images for DOTMATRI: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:04<00:00, 110.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Done! Total images generated: 500\nüìÅ Output per font: saved under /kaggle/working/generated_receipt_images/DOTMATRI/\n","output_type":"stream"},{"name":"stderr","text":"Generating images for Epson Pixeled: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:04<00:00, 101.05it/s]","output_type":"stream"},{"name":"stdout","text":"‚úÖ Done! Total images generated: 500\nüìÅ Output per font: saved under /kaggle/working/generated_receipt_images/Epson Pixeled/\nüéâ All fonts processed!\nüìä Total images generated overall: 3500\nüìÅ Output base directory: /kaggle/working/generated_receipt_images/\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import shutil\n\n# Path folder yang ingin di-zip\nfolder_to_zip = \"/kaggle/working/generated_receipt_images\"\noutput_zip_path = \"/kaggle/working/generated_receipt_images.zip\"\n\n# Membuat zip dari folder\nshutil.make_archive(output_zip_path.replace(\".zip\", \"\"), 'zip', folder_to_zip)\n\nprint(f\"‚úÖ Folder telah di-zip ke: {output_zip_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T06:21:14.361037Z","iopub.execute_input":"2025-05-22T06:21:14.361339Z","iopub.status.idle":"2025-05-22T06:21:15.484965Z","shell.execute_reply.started":"2025-05-22T06:21:14.361319Z","shell.execute_reply":"2025-05-22T06:21:15.484216Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Folder telah di-zip ke: /kaggle/working/generated_receipt_images.zip\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!git clone https://github.com/clovaai/deep-text-recognition-benchmark","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T06:21:18.768653Z","iopub.execute_input":"2025-05-22T06:21:18.769209Z","iopub.status.idle":"2025-05-22T06:21:19.744923Z","shell.execute_reply.started":"2025-05-22T06:21:18.769186Z","shell.execute_reply":"2025-05-22T06:21:19.744191Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'deep-text-recognition-benchmark'...\nremote: Enumerating objects: 499, done.\u001b[K\nremote: Counting objects: 100% (225/225), done.\u001b[K\nremote: Compressing objects: 100% (25/25), done.\u001b[K\nremote: Total 499 (delta 208), reused 200 (delta 200), pack-reused 274 (from 1)\u001b[K\nReceiving objects: 100% (499/499), 3.05 MiB | 18.62 MiB/s, done.\nResolving deltas: 100% (308/308), done.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Augmentasi\ndef augment_image(pil_img):\n    img = np.array(pil_img)\n\n    # Gaussian Noise\n    if random.random() < 0.5:\n        noise = np.random.normal(0, 15, img.shape).astype(np.uint8)\n        img = cv2.add(img, noise)\n\n    # Blur\n    if random.random() < 0.5:\n        k = random.choice([1, 3])\n        img = cv2.GaussianBlur(img, (k, k), 0)\n\n    # Distortion\n    if random.random() < 0.5:\n        rows, cols = img.shape[:2]\n        src = np.float32([[5, 5], [cols - 5, 5], [5, rows - 5]])\n        dst = src + np.random.randint(-5, 5, src.shape).astype(np.float32)\n        M = cv2.getAffineTransform(src, dst)\n        img = cv2.warpAffine(img, M, (cols, rows), borderMode=cv2.BORDER_REPLICATE)\n\n    return Image.fromarray(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T06:21:24.235695Z","iopub.execute_input":"2025-05-22T06:21:24.236309Z","iopub.status.idle":"2025-05-22T06:21:24.241784Z","shell.execute_reply.started":"2025-05-22T06:21:24.236287Z","shell.execute_reply":"2025-05-22T06:21:24.241071Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# === SETUP ===\ntrain_lmdb_dir = \"/kaggle/working/deep-text-recognition-benchmark/lmdb_train\"\nval_lmdb_dir = \"/kaggle/working/deep-text-recognition-benchmark/lmdb_val\"\n\nenv_train = lmdb.open(train_lmdb_dir, map_size=1099511627776)\nenv_val = lmdb.open(val_lmdb_dir, map_size=1099511627776)\ntxn_train = env_train.begin(write=True)\ntxn_val = env_val.begin(write=True)\n\nimg_id_train = 0\nimg_id_val = 0\n\nlabel_train_lines = []\nlabel_val_lines = []\n\nfont_limit = 500\nsplit_ratio = 0.9\ntrain_count = int(font_limit * split_ratio)\nval_count = font_limit - train_count\n\nfor font_path in tqdm(receipt_fonts):\n    font = ImageFont.truetype(font_path, 28)\n    samples = []\n\n    for i in range(font_limit):\n        text = all_combinations[random.randint(0, len(all_combinations) - 1)]\n        img = Image.new(\"L\", (400, 50), 255)\n        draw = ImageDraw.Draw(img)\n        draw.text((5, 5), text, font=font, fill=0)\n        img = augment_image(img)\n        samples.append((text, img))\n\n    random.shuffle(samples)\n    train_samples = samples[:train_count]\n    val_samples = samples[train_count:]\n\n    # === Simpan ke TRAIN ===\n    for text, img in train_samples:\n        img_byte_arr = io.BytesIO()\n        img.save(img_byte_arr, format='PNG')\n        image_key = f'image-{img_id_train:09}'.encode()\n        label_key = f'label-{img_id_train:09}'.encode()\n\n        txn_train.put(image_key, img_byte_arr.getvalue())\n        txn_train.put(label_key, text.encode())\n\n        label_train_lines.append(f\"image-{img_id_train:09}.png\\t{text}\\t[[0,0],[100,0],[100,30],[0,30]]\\n\")\n        img_id_train += 1\n\n        if img_id_train % 1000 == 0:\n            txn_train.commit()\n            txn_train = env_train.begin(write=True)\n\n    # === Simpan ke VAL ===\n    for text, img in val_samples:\n        img_byte_arr = io.BytesIO()\n        img.save(img_byte_arr, format='PNG')\n        image_key = f'image-{img_id_val:09}'.encode()\n        label_key = f'label-{img_id_val:09}'.encode()\n\n        txn_val.put(image_key, img_byte_arr.getvalue())\n        txn_val.put(label_key, text.encode())\n\n        label_val_lines.append(f\"image-{img_id_val:09}.png\\t{text}\\t[[0,0],[100,0],[100,30],[0,30]]\\n\")\n        img_id_val += 1\n\n        if img_id_val % 1000 == 0:\n            txn_val.commit()\n            txn_val = env_val.begin(write=True)\n\n# === Final Commit + Simpan Jumlah ===\ntxn_train.put('num-samples'.encode(), str(img_id_train).encode())\nprint(f\"‚úÖ Done. Total: {img_id_train} train images written to LMDB.\")\ntxn_val.put('num-samples'.encode(), str(img_id_val).encode())\nprint(f\"‚úÖ Done. Total: {img_id_val} val images written to LMDB.\")\ntxn_train.commit()\ntxn_val.commit()\nenv_train.close()\nenv_val.close()\n\n# === Simpan label.txt ===\nwith open(\"label_train.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.writelines(label_train_lines)\n\nwith open(\"label_val.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.writelines(label_val_lines)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T06:21:28.627958Z","iopub.execute_input":"2025-05-22T06:21:28.628440Z","iopub.status.idle":"2025-05-22T06:21:59.276370Z","shell.execute_reply.started":"2025-05-22T06:21:28.628416Z","shell.execute_reply":"2025-05-22T06:21:59.275744Z"}},"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:30<00:00,  4.37s/it]","output_type":"stream"},{"name":"stdout","text":"‚úÖ Done. Total: 3150 train images written to LMDB.\n‚úÖ Done. Total: 350 val images written to LMDB.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# FINETUNING","metadata":{}},{"cell_type":"code","source":"import os\n\nexp_name = \"TPS-ResNet-BiLSTM-Attn-Seed1111\"\nexp_dir = f\"/kaggle/working/deep-text-recognition-benchmark/{exp_name}\"\nlog_path = os.path.join(exp_dir, \"log_dataset.txt\")\n\n# Buat folder jika belum ada\nos.makedirs(exp_dir, exist_ok=True)\n\n# Buat file log_dataset.txt kosong jika belum ada\nif not os.path.exists(log_path):\n    with open(log_path, \"w\") as f:\n        f.write(\"\")  # atau isi pesan awal jika mau\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:01:11.540218Z","iopub.execute_input":"2025-05-21T16:01:11.540643Z","iopub.status.idle":"2025-05-21T16:01:11.546197Z","shell.execute_reply.started":"2025-05-21T16:01:11.540614Z","shell.execute_reply":"2025-05-21T16:01:11.545441Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"%cd /kaggle/working/deep-text-recognition-benchmark/\n\n!python train.py \\\n  --train_data lmdb_train \\\n  --valid_data lmdb_val \\\n  --select_data \"\" \\\n  --batch_ratio 1.0 \\\n  --Transformation TPS \\\n  --FeatureExtraction ResNet \\\n  --SequenceModeling BiLSTM \\\n  --Prediction Attn \\\n  --batch_size 2 \\\n  --data_filtering_off \\\n  --workers 0 \\\n  --batch_max_length 300 \\\n  --num_iter 100 \\\n  --valInterval 20 \\\n  --saved_model TPS-ResNet-BiLSTM-Attn.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:55:17.265917Z","iopub.execute_input":"2025-05-21T18:55:17.266696Z","iopub.status.idle":"2025-05-21T20:12:19.395767Z","shell.execute_reply.started":"2025-05-21T18:55:17.266667Z","shell.execute_reply":"2025-05-21T20:12:19.394991Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/deep-text-recognition-benchmark\n------ Use multi-GPU setting ------\nif you stuck too long time with multi-GPU setting, try to set --workers 0\n dataset length: 3500\n--------------------------------------------------------------------------------\nmodel input parameters 32 100 20 1 512 256 38 300 TPS ResNet BiLSTM Attn\nSkip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\nSkip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\nloading pretrained model from TPS-ResNet-BiLSTM-Attn.pth\nModel:\nDataParallel(\n  (module): Model(\n    (Transformation): TPS_SpatialTransformerNetwork(\n      (LocalizationNetwork): LocalizationNetwork(\n        (conv): Sequential(\n          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (6): ReLU(inplace=True)\n          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (10): ReLU(inplace=True)\n          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (14): ReLU(inplace=True)\n          (15): AdaptiveAvgPool2d(output_size=1)\n        )\n        (localization_fc1): Sequential(\n          (0): Linear(in_features=512, out_features=256, bias=True)\n          (1): ReLU(inplace=True)\n        )\n        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n      )\n      (GridGenerator): GridGenerator()\n    )\n    (FeatureExtraction): ResNet_FeatureExtractor(\n      (ConvNet): ResNet(\n        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        (layer1): Sequential(\n          (0): BasicBlock(\n            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n            (downsample): Sequential(\n              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n        )\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        (layer2): Sequential(\n          (0): BasicBlock(\n            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n            (downsample): Sequential(\n              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (1): BasicBlock(\n            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n          )\n        )\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n        (layer3): Sequential(\n          (0): BasicBlock(\n            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n            (downsample): Sequential(\n              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (1): BasicBlock(\n            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n          )\n          (2): BasicBlock(\n            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n          )\n          (3): BasicBlock(\n            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n          )\n          (4): BasicBlock(\n            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n          )\n        )\n        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (layer4): Sequential(\n          (0): BasicBlock(\n            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n          )\n          (1): BasicBlock(\n            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n          )\n          (2): BasicBlock(\n            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU(inplace=True)\n          )\n        )\n        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n    (SequenceModeling): Sequential(\n      (0): BidirectionalLSTM(\n        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n        (linear): Linear(in_features=512, out_features=256, bias=True)\n      )\n      (1): BidirectionalLSTM(\n        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n        (linear): Linear(in_features=512, out_features=256, bias=True)\n      )\n    )\n    (Prediction): Attention(\n      (attention_cell): AttentionCell(\n        (i2h): Linear(in_features=256, out_features=256, bias=False)\n        (h2h): Linear(in_features=256, out_features=256, bias=True)\n        (score): Linear(in_features=256, out_features=1, bias=False)\n        (rnn): LSTMCell(294, 256)\n      )\n      (generator): Linear(in_features=256, out_features=38, bias=True)\n    )\n  )\n)\nTrainable params num :  49555182\nOptimizer:\nAdadelta (\nParameter Group 0\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 1\n    maximize: False\n    rho: 0.95\n    weight_decay: 0\n)\n------------ Options -------------\nexp_name: TPS-ResNet-BiLSTM-Attn-Seed1111\ntrain_data: lmdb_output\nvalid_data: lmdb_output\nmanualSeed: 1111\nworkers: 0\nbatch_size: 4\nnum_iter: 100\nvalInterval: 20\nsaved_model: TPS-ResNet-BiLSTM-Attn.pth\nFT: False\nadam: False\nlr: 1\nbeta1: 0.9\nrho: 0.95\neps: 1e-08\ngrad_clip: 5\nbaiduCTC: False\nselect_data: ['']\nbatch_ratio: ['1.0']\ntotal_data_usage_ratio: 1.0\nbatch_max_length: 300\nimgH: 32\nimgW: 100\nrgb: False\ncharacter: 0123456789abcdefghijklmnopqrstuvwxyz\nsensitive: False\nPAD: False\ndata_filtering_off: True\nTransformation: TPS\nFeatureExtraction: ResNet\nSequenceModeling: BiLSTM\nPrediction: Attn\nnum_fiducial: 20\ninput_channel: 1\noutput_channel: 512\nhidden_size: 256\nnum_gpu: 2\nnum_class: 38\n---------------------------------------\n\n[ERROR] Image buffer is None for key: image-000003500\n[1/100] Train loss: 4.96067, Valid loss: 6.05103, Elapsed_time: 2.95556\nCurrent_accuracy : 0.000, Current_norm_ED  : 0.00\nBest_accuracy    : 0.000, Best_norm_ED     : 0.00\n--------------------------------------------------------------------------------\nGround Truth              | Prediction                | Confidence Score & T/F\n--------------------------------------------------------------------------------\nheocaolaompanyocaola96045s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | intercomplecompliation    | 0.0000\tFalse\nyllingpostei949s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | tyllingposterings         | 0.0021\tFalse\nastasausmedbasilikum1931s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | postasuonation            | 0.0006\tFalse\nooplatlandlen7914s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | coopristionalizien        | 0.0018\tFalse\n--------------------------------------------------------------------------------\n[ERROR] Image buffer is None for key: image-000003500\n[20/100] Train loss: 3.12463, Valid loss: 4.72165, Elapsed_time: 482.99842\nCurrent_accuracy : 0.000, Current_norm_ED  : 0.01\nBest_accuracy    : 0.000, Best_norm_ED     : 0.01\n--------------------------------------------------------------------------------\nGround Truth              | Prediction                | Confidence Score & T/F\n--------------------------------------------------------------------------------\nooponcorpirnsum3873s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | cooplonoplinisminstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinstinsti | 0.0000\tFalse\narlsbergrginal3819s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | aristergiongingiastersassessenstargisstersississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississississ | 0.0000\tFalse\nollyeantterdenoriginale1016s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | poilsyfematerdendendendresondendenorosororistierdendendresondendenorosoronoristierdendendresondendenorosoronoristierdendendresondendenorosoronoristierdendendresondendenorosoronoristierdendendresondendenorosoronoristierdendendresondendenorosoronoristierdendendresondendenorosoronoristierdendendresonde | 0.0000\tFalse\nommerklenning2024s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | issaskestersonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonssonss | 0.0000\tFalse\n--------------------------------------------------------------------------------\n[ERROR] Image buffer is None for key: image-000003500\n[40/100] Train loss: 2.54924, Valid loss: 3.42568, Elapsed_time: 1649.41704\nCurrent_accuracy : 0.000, Current_norm_ED  : 0.01\nBest_accuracy    : 0.000, Best_norm_ED     : 0.01\n--------------------------------------------------------------------------------\nGround Truth              | Prediction                | Confidence Score & T/F\n--------------------------------------------------------------------------------\naltstenger8343s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | ottsterger328sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss119sss11 | 0.0000\tFalse\nmak4801s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | retterstookenstrostsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmsttsmstts | 0.0000\tFalse\nowerkingero3618s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | overtinglear938sss119sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss1199sss119 | 0.0000\tFalse\nasabintter2996s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | estieterar93ssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss | 0.0000\tFalse\n--------------------------------------------------------------------------------\n[ERROR] Image buffer is None for key: image-000003500\n[60/100] Train loss: 2.51483, Valid loss: 3.28643, Elapsed_time: 2850.55832\nCurrent_accuracy : 0.000, Current_norm_ED  : 0.01\nBest_accuracy    : 0.000, Best_norm_ED     : 0.01\n--------------------------------------------------------------------------------\nGround Truth              | Prediction                | Confidence Score & T/F\n--------------------------------------------------------------------------------\nuiceditrusinkrapefruit3317s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | addaraborkerakerrandarkerakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerrakerr | 0.0000\tFalse\navsaltllevillepper1503s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | asseltallevilllypplipstillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppillppil | 0.0000\tFalse\nksekjttbuljong52966s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | kssijjuliangh71ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477ss477 | 0.0000\tFalse\nororydderietororkla2410s[GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO][GO | riblortanillandarker111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske111sske | 0.0000\tFalse\n--------------------------------------------------------------------------------\n^C\nTraceback (most recent call last):\n  File \"/kaggle/working/deep-text-recognition-benchmark/train.py\", line 317, in <module>\n    train(opt)\n  File \"/kaggle/working/deep-text-recognition-benchmark/train.py\", line 181, in train\n    valid_loss, current_accuracy, current_norm_ED, preds, confidence_score, labels, infer_time, length_of_data = validation(\n                                                                                                                 ^^^^^^^^^^^\n  File \"/kaggle/working/deep-text-recognition-benchmark/test.py\", line 121, in validation\n    preds = model(image, text_for_pred, is_train=False)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\", line 193, in forward\n    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\", line 212, in parallel_apply\n    return parallel_apply(\n           ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/parallel_apply.py\", line 118, in parallel_apply\n    thread.join()\n  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n    self._wait_for_tstate_lock()\n  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n    if lock.acquire(block, timeout):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":153},{"cell_type":"code","source":"# edit dataset.py\n\ndataset_py_code = \"\"\"\nimport os\nimport sys\nimport six\nimport random\nimport string\nimport warnings\nfrom itertools import accumulate\n\nimport lmdb\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torch.utils.data as data\nfrom torchvision import transforms\n\nclass ResizeNormalize(object):\n    def __init__(self, size, interpolation=Image.BICUBIC):\n        self.size = size\n        self.interpolation = interpolation\n        self.toTensor = transforms.ToTensor()\n\n    def __call__(self, img):\n        img = img.resize(self.size, self.interpolation)\n        img = self.toTensor(img)\n        img.sub_(0.5).div_(0.5)\n        return img\n\nclass AlignCollate:\n    def __init__(self, imgH=32, imgW=100, keep_ratio_with_pad=False, min_ratio=1):\n        self.imgH = imgH\n        self.imgW = imgW\n        self.keep_ratio_with_pad = keep_ratio_with_pad\n        self.min_ratio = min_ratio\n\n    def __call__(self, batch):\n        # Filter None (yang muncul karena missing image)\n        batch = [b for b in batch if b is not None]\n        if len(batch) == 0:\n            return None, None  # Bisa juga raise error atau handle sesuai kebutuhan\n\n        images, labels = zip(*batch)\n\n        if self.keep_ratio_with_pad:\n            ratios = []\n            for image in images:\n                w, h = image.size\n                ratios.append(w / float(h))\n            ratios.sort()\n            max_ratio = ratios[-1]\n            imgW = int(np.floor(max_ratio * self.imgH))\n            imgW = max(self.imgH * self.min_ratio, imgW)\n        else:\n            imgW = self.imgW\n\n        transform = ResizeNormalize((imgW, self.imgH))\n        images = [transform(image) for image in images]\n        images = torch.stack(images, 0)\n\n        return images, labels\n\nclass LmdbDataset(data.Dataset):\n    def __init__(self, root, transform=None):\n        self.env = lmdb.open(\n            root,\n            max_readers=1,\n            readonly=True,\n            lock=False,\n            readahead=False,\n            meminit=False\n        )\n\n        if not self.env:\n            print(f'Cannot open LMDB from {root}')\n            sys.exit(0)\n\n        with self.env.begin(write=False) as txn:\n            n_samples = int(txn.get('num-samples'.encode()).decode())\n            self.n_samples = n_samples\n\n        self.transform = transform\n\n    def __len__(self):\n        return self.n_samples\n\n    def __getitem__(self, index):\n        assert index < len(self), 'Index range error'  # changed to < len, since index is zero-based\n    \n        # LMDB keys start from 1, so increment index\n        lmdb_index = index + 1\n    \n        with self.env.begin(write=False) as txn:\n            img_key = f'image-{lmdb_index:09d}'.encode()\n            imgbuf = txn.get(img_key)\n    \n            # If image buffer is missing, try next index (skip)\n            if imgbuf is None:\n                print(f'[ERROR] Image buffer is None for key: {img_key.decode()}')\n                if lmdb_index + 1 < self.n_samples:\n                    return self.__getitem__(lmdb_index)  # recursive call with next index (lmdb_index already +1)\n                else:\n                    return None  # no more images to try\n    \n            buf = six.BytesIO()\n            buf.write(imgbuf)\n            buf.seek(0)\n    \n            try:\n                img = Image.open(buf).convert('L')\n            except IOError:\n                print(f'[ERROR] Corrupted image at key: {img_key.decode()}')\n                if lmdb_index + 1 < self.n_samples:\n                    return self.__getitem__(lmdb_index)\n                else:\n                    return None\n    \n            label_key = f'label-{lmdb_index:09d}'.encode()\n            label = txn.get(label_key).decode('utf-8')\n    \n            if self.transform:\n                img = self.transform(img)\n                \n            return (img, label)\n\ndef hierarchical_dataset(root, opt=None):\n    dataset = LmdbDataset(root)\n    log_msg = f\"{root} dataset length: {len(dataset)}\"\n    return dataset, log_msg\n\nclass Batch_Balanced_Dataset:\n    def __init__(self, opt):\n        os.makedirs(opt.exp_name, exist_ok=True)\n        log = open(f'{opt.exp_name}/log_dataset.txt', 'a')\n        align_collate = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)\n        self.data_loader = {}\n        self.dataloader_iter = {}\n        batch_size = opt.batch_size\n        data_ratio = opt.batch_ratio\n\n        select_data = opt.select_data\n        batch_ratio = opt.batch_ratio\n        assert len(select_data) == len(batch_ratio)\n\n        for selected_d, ratio in zip(select_data, batch_ratio):\n            _path = os.path.join(opt.train_data, selected_d)\n            dataset = LmdbDataset(_path)\n            print(f'{selected_d} dataset length: {len(dataset)}')\n            log.write(f'{selected_d} dataset length: {len(dataset)}\\\\n')\n            batch_size_ratio = max(round(batch_size * float(ratio)), 1)\n\n            data_loader = torch.utils.data.DataLoader(\n                dataset,\n                batch_size=batch_size_ratio,\n                shuffle=True,\n                num_workers=int(opt.workers),\n                collate_fn=align_collate,\n                pin_memory=True\n            )\n\n            self.data_loader[selected_d] = data_loader\n            self.dataloader_iter[selected_d] = iter(data_loader)\n        log.close()\n\n    def get_batch(self):\n        balanced_batch = []\n        for selected_d in self.data_loader:\n            try:\n                data = next(self.dataloader_iter[selected_d])\n            except StopIteration:\n                self.dataloader_iter[selected_d] = iter(self.data_loader[selected_d])\n                data = next(self.dataloader_iter[selected_d])\n            balanced_batch.append(data)\n        image = torch.cat([x[0] for x in balanced_batch], 0)\n        label = sum([x[1] for x in balanced_batch], [])\n        return image, label\n\"\"\"\n\n# Simpan ke dataset.py\nwith open(\"/kaggle/working/deep-text-recognition-benchmark/dataset.py\", \"w\") as f:\n    f.write(dataset_py_code)\n\nprint(\"‚úÖ dataset.py berhasil ditulis ulang dengan modifikasi.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:27:00.195668Z","iopub.execute_input":"2025-05-21T18:27:00.195972Z","iopub.status.idle":"2025-05-21T18:27:00.204417Z","shell.execute_reply.started":"2025-05-21T18:27:00.195947Z","shell.execute_reply":"2025-05-21T18:27:00.203817Z"}},"outputs":[{"name":"stdout","text":"‚úÖ dataset.py berhasil ditulis ulang dengan modifikasi.\n","output_type":"stream"}],"execution_count":151},{"cell_type":"code","source":"!cp /kaggle/input/ocr/other/default/1/TPS-ResNet-BiLSTM-Attn.pth /kaggle/working/deep-text-recognition-benchmark/TPS-ResNet-BiLSTM-Attn.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T15:49:39.865208Z","iopub.execute_input":"2025-05-21T15:49:39.865976Z","iopub.status.idle":"2025-05-21T15:49:43.184204Z","shell.execute_reply.started":"2025-05-21T15:49:39.865944Z","shell.execute_reply":"2025-05-21T15:49:43.183400Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"!cp /kaggle/input/fix-bug/utils.py /kaggle/working/deep-text-recognition-benchmark/utils.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:17:33.654925Z","iopub.execute_input":"2025-05-21T17:17:33.655750Z","iopub.status.idle":"2025-05-21T17:17:33.790039Z","shell.execute_reply.started":"2025-05-21T17:17:33.655718Z","shell.execute_reply":"2025-05-21T17:17:33.789261Z"}},"outputs":[],"execution_count":136},{"cell_type":"code","source":"!cp /kaggle/input/fix-bug/train.py /kaggle/working/deep-text-recognition-benchmark/train.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:14:46.683012Z","iopub.execute_input":"2025-05-21T17:14:46.683739Z","iopub.status.idle":"2025-05-21T17:14:46.823127Z","shell.execute_reply.started":"2025-05-21T17:14:46.683709Z","shell.execute_reply":"2025-05-21T17:14:46.822390Z"}},"outputs":[],"execution_count":132},{"cell_type":"code","source":"import shutil\n\n# Path folder yang ingin di-zip\nfolder_to_zip = \"/kaggle/working/deep-text-recognition-benchmark\"\noutput_zip_path = \"/kaggle/working/deep-text-recognition-benchmark.zip\"\n\n# Membuat zip dari folder\nshutil.make_archive(output_zip_path.replace(\".zip\", \"\"), 'zip', folder_to_zip)\n\nprint(f\"‚úÖ Folder telah di-zip ke: {output_zip_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T20:13:27.248794Z","iopub.execute_input":"2025-05-21T20:13:27.249057Z","iopub.status.idle":"2025-05-21T20:13:57.258843Z","shell.execute_reply.started":"2025-05-21T20:13:27.249036Z","shell.execute_reply":"2025-05-21T20:13:57.258104Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Folder telah di-zip ke: /kaggle/working/deep-text-recognition-benchmark.zip\n","output_type":"stream"}],"execution_count":154}]}
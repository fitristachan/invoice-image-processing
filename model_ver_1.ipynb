{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "l7AbYIPTK4Ei"
      },
      "outputs": [],
      "source": [
        "# %pip install datasets\n",
        "# %pip install Pillow\n",
        "# %pip install numpy\n",
        "# %pip install matplotlib\n",
        "# %pip install import_ipynb\n",
        "# %pip install tensorflow\n",
        "# %pip install tensorflow.keras\n",
        "\n",
        "\n",
        "# # !pip install torch\n",
        "# # !pip install torchvision\n",
        "# # !pip install scikit-image\n",
        "# # !pip install scipy\n",
        "# %pip install easyocr\n",
        "\n",
        "# # library from etl\n",
        "# %pip install datasets\n",
        "# %pip install numpy\n",
        "# %pip install Pillow\n",
        "# %pip install opencv-python\n",
        "# %pip install json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGb_mueSWqNf"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "# from tensorflow.keras import layers\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07me5aotGmoh",
        "outputId": "1fd84f32-1efb-49ae-d7bf-553da1810581"
      },
      "outputs": [],
      "source": [
        "# from google.colab import userdata\n",
        "\n",
        "# # Retrieve the GitHub token from userdata\n",
        "# myGithub = userdata.get('githubKey')\n",
        "\n",
        "# !git clone https://{myGithub}@github.com/fitristachan/invoice-image-processing.git /content/invoice-image-processing\n",
        "# !git -C invoice-image-processing pull\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAcGkB2eD3XN",
        "outputId": "13951a39-c468-4194-8a3d-5f65f2a6c4e0"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# import os\n",
        "\n",
        "# sys.path.append('/content/invoice-image-processing')\n",
        "# print(os.listdir('/content/invoice-image-processing'))\n",
        "\n",
        "# !jupyter nbconvert --to script '/content/invoice-image-processing/data_etl_invoice.ipynb' --output data_etl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_etl import DatasetReceipt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inisialisasi dataset\n",
        "dataset_local = DatasetReceipt(dataset_name=\"naver-clova-ix/cord-v2\", split=\"train\")\n",
        "dataset_inter = DatasetReceipt(dataset_name=\"katanaml-org/invoices-donut-data-v1\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.applications.ResNet50V2 import ResNet50V2\n",
        "\n",
        "# keras.applications.ResNet50V2(\n",
        "#     include_top=True,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_tensor=None,\n",
        "#     input_shape=None,\n",
        "#     pooling=None,\n",
        "#     classes=1000,\n",
        "#     classifier_activation=\"softmax\",\n",
        "#     name=\"resnet50v2\",\n",
        "# )\n",
        "\n",
        "pre_trained_model = ResNet50V2(input_shape = (600, 600, 3),\n",
        "                                include_top = False,\n",
        "                                pooling='max'\n",
        "                                )\n",
        "\n",
        "pre_trained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load Dataset (Gunakan DatasetReceipt class yang sudah dibuat sebelumnya)\n",
        "train_dataset = DatasetReceipt(dataset_name=\"naver-clova-ix/cord-v2\", split=\"train\")\n",
        "val_dataset = DatasetReceipt(dataset_name=\"katanaml-org/invoices-donut-data-v1\", split=\"train\")\n",
        "\n",
        "# Function to generate batches\n",
        "def dataset_generator(dataset, batch_size=16):\n",
        "    while True:\n",
        "        images, labels = [], []\n",
        "        for i in range(batch_size):\n",
        "            sample = dataset[i]\n",
        "            images.append(sample[\"image\"])\n",
        "            labels.append(sample[\"label\"])  # Ubah ke format numerik jika perlu\n",
        "\n",
        "        yield np.array(images), np.array(labels)\n",
        "\n",
        "# Pretrained Model (Feature Extractor)\n",
        "base_model = ResNet50V2(input_shape=(600, 600, 3), include_top=False, pooling='max')\n",
        "base_model.trainable = False  # Freeze pretrained layers\n",
        "\n",
        "# Tambahkan Custom Layers untuk Bounding Box + Label Classification\n",
        "inputs = Input(shape=(600, 600, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Output untuk bounding box (4 nilai: x_min, y_min, x_max, y_max)\n",
        "bbox_output = Dense(4, activation='linear', name=\"bounding_box\")(x)\n",
        "\n",
        "# Output untuk klasifikasi teks (misalnya 5 kelas)\n",
        "class_output = Dense(5, activation='softmax', name=\"class_label\")(x)\n",
        "\n",
        "# Gabungkan menjadi satu model\n",
        "model = Model(inputs, outputs=[bbox_output, class_output])\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss={\n",
        "        \"bounding_box\": \"mse\",  # Mean Squared Error untuk bounding box\n",
        "        \"class_label\": \"categorical_crossentropy\",  # Klasifikasi teks\n",
        "    },\n",
        "    metrics={\"bounding_box\": \"mae\", \"class_label\": \"accuracy\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/dataset/model/model_checkpoint_resnet50v2.h5\"\n",
        "checkpoint_callback = ModelCheckpoint(checkpoint_path, save_best_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Callbacks(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs['accuracy'] > 0.95 and logs['val_accuracy'] > 95:\n",
        "            print(\"\\nAccuracy reached 95%! Stopping training.\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "stop_callback = Callbacks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "csv_logger = CSVLogger('training_log.csv', separator=',', append=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Augmentation\n",
        "train_generator = dataset_generator(train_dataset, batch_size=16)\n",
        "val_generator = dataset_generator(val_dataset, batch_size=16)\n",
        "\n",
        "# Train Model\n",
        "model.fit(train_generator, \n",
        "          validation_data=val_generator,\n",
        "          epochs=25,\n",
        "          steps_per_epoch=1000,\n",
        "          validation_steps=200,\n",
        "          callbacks=[checkpoint_callback, csv_logger])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load training log\n",
        "log_data = pd.read_csv(\"training_log.csv\")\n",
        "\n",
        "# Buat figure untuk dua grafik\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.plot(log_data[\"epoch\"], log_data[\"bounding_box_mae\"], label=\"Training MAE\")\n",
        "plt.plot(log_data[\"epoch\"], log_data[\"val_bounding_box_mae\"], label=\"Validation MAE\")\n",
        "plt.plot(log_data[\"epoch\"], log_data[\"class_label_accuracy\"], label=\"Training Accuracy\")\n",
        "plt.plot(log_data[\"epoch\"], log_data[\"val_class_label_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy / MAE\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Model Loss\")\n",
        "plt.plot(log_data[\"epoch\"], log_data[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(log_data[\"epoch\"], log_data[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Save Model\n",
        "# model.save(\"faster_rcnn_resnet50v2.h5\")\n",
        "# print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ged1zlumREAq"
      },
      "source": [
        "**Text Extraction**\n",
        "\n",
        "> using easyocr\n",
        "\n",
        "> support bahasa indonesia and english\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f01YTPk-JDk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ],
      "source": [
        "reader = easyocr.Reader(['en', 'id'])\n",
        "\n",
        "def is_receipt(text):\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    if 'total' or 'amount' or 'jumlah' and 'price' or 'harga' in text_lower:\n",
        "        print(\"This is a valid receipt.\")\n",
        "    else:\n",
        "        print(\"This is not a valid receipt.\")\n",
        "\n",
        "\n",
        "def process_image(image):\n",
        "    # Convert PIL Image to numpy array\n",
        "    image_np = np.array(image)\n",
        "    if image_np.dtype != np.uint8:\n",
        "        image_np = (image_np * 255).astype(np.uint8)  # Normalisasi jika float64\n",
        "\n",
        "    # Extract text using EasyOCR\n",
        "    results = reader.readtext(image_np)\n",
        "\n",
        "    # Combine all detected text into a single string\n",
        "    extracted_text = ' '.join([result[1] for result in results])\n",
        "\n",
        "    # Check if the extracted text is a receipt\n",
        "    is_receipt(extracted_text)\n",
        "\n",
        "    print(\"Extracted Text:\")\n",
        "    print(extracted_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2481x3508>,\n",
              " 'ground_truth': '{\"gt_parse\": {\"header\": {\"invoice_no\": \"42485588\", \"invoice_date\": \"03/15/2012\", \"seller\": \"Zuniga and Sons 455 Jones Trace Suite 479 Port Sarah, NM 29233\", \"client\": \"Knight-Brown 316 Garrett Valleys Lake John, LA 21710\", \"seller_tax_id\": \"923-88-8185\", \"client_tax_id\": \"970-99-7937\", \"iban\": \"GB47NOK145420514797164\"}, \"items\": [{\"item_desc\": \"3 Gal 12L Moonshine Still Stainless Steel Water Wine Alcohol Distiller Equipment\", \"item_qty\": \"1,00\", \"item_net_price\": \"99,92\", \"item_net_worth\": \"99,92\", \"item_vat\": \"10%\", \"item_gross_worth\": \"109,91\"}, {\"item_desc\": \"Custom wine glass\", \"item_qty\": \"5,00\", \"item_net_price\": \"19,00\", \"item_net_worth\": \"95,00\", \"item_vat\": \"10%\", \"item_gross_worth\": \"104,50\"}], \"summary\": {\"total_net_worth\": \"$ 194,92\", \"total_vat\": \"$ 19,49\", \"total_gross_worth\": \"214,41\"}}}'}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# data_tuning_local = load_dataset(\"naver-clova-ix/cord-v2\", split=\"train\")\n",
        "# data_tuning_inter = load_dataset(\"katanaml-org/invoices-donut-data-v1\", split=\"train\")\n",
        "# data_tuning_inter[5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# import json\n",
        "\n",
        "# def convert_dataset_local(dataset, output_file):\n",
        "#     annotations = []\n",
        "\n",
        "#     # Pastikan folder untuk menyimpan gambar ada\n",
        "#     os.makedirs(\"dataset_images\", exist_ok=True)\n",
        "\n",
        "#     for i, data in enumerate(dataset):\n",
        "#         image = data[\"image\"]  # Objek gambar dari PIL\n",
        "#         ground_truth = json.loads(data[\"ground_truth\"])  # Parsing JSON string\n",
        "\n",
        "#         # Simpan gambar ke folder agar bisa digunakan oleh EasyOCR\n",
        "#         image_path = f\"dataset_images/image_{i}.jpg\"\n",
        "#         image.save(image_path)  \n",
        "\n",
        "#         # Ambil teks dan bounding box dari ground truth\n",
        "#         text = ground_truth[\"gt_parse\"]  # Semua teks dan informasi struk\n",
        "#         words = []\n",
        "#         for line in ground_truth[\"valid_line\"]:  # Ambil setiap baris\n",
        "#             for word in line[\"words\"]:  # Ambil setiap kata dalam baris\n",
        "#                 words.append({\n",
        "#                     \"text\": word[\"text\"],\n",
        "#                     \"quad\": word[\"quad\"],\n",
        "#                     \"row_id\": word[\"row_id\"],\n",
        "#                     \"category\": line[\"category\"],\n",
        "#                     \"group_id\": line[\"group_id\"]\n",
        "#                 })\n",
        "\n",
        "#         # Simpan dalam format yang sesuai untuk EasyOCR\n",
        "#         annotations.append({\n",
        "#             \"image\": image_path,\n",
        "#             \"text\": text,\n",
        "#             \"words\": words\n",
        "#         })\n",
        "\n",
        "#     # Simpan hasil dalam file JSON\n",
        "#     with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "#         json.dump(annotations, f, indent=4, ensure_ascii=False)\n",
        "        \n",
        "\n",
        "# def convert_dataset_inter(dataset, output_file):\n",
        "#     \"\"\"\n",
        "#     Mengonversi dataset faktur/invoice ke format JSON untuk EasyOCR.\n",
        "#     \"\"\"\n",
        "#     annotations = []\n",
        "    \n",
        "#     for i, data in enumerate(dataset):\n",
        "#         image = data[\"image\"]  # PIL Image\n",
        "#         ground_truth = json.loads(data[\"ground_truth\"])[\"gt_parse\"]  # Parse JSON\n",
        "        \n",
        "#         # Simpan gambar\n",
        "#         image_path = f\"dataset_images/invoice_{i}.jpg\"\n",
        "#         os.makedirs(\"dataset_images\", exist_ok=True)\n",
        "#         image.save(image_path)\n",
        "        \n",
        "#         words = []\n",
        "#         items = ground_truth.get(\"items\", [])  # Pastikan mengambil 'items' dengan default []\n",
        "#         if items:\n",
        "#             for item in items:\n",
        "#                 words.append({\n",
        "#                     \"text\": item.get(\"item_desc\", \"UNKNOWN_ITEM\"),\n",
        "#                     \"quad\": None,\n",
        "#                     \"row_id\": None,\n",
        "#                     \"group_id\": None\n",
        "#                 })\n",
        "        \n",
        "#         annotations.append({\n",
        "#             \"image\": image_path,\n",
        "#             \"text\": ground_truth,  # Simpan seluruh teks yang diparsing\n",
        "#             \"bbox\": words\n",
        "#         })\n",
        "    \n",
        "#         # Pastikan folder Google Drive tujuan benar\n",
        "#         drive_folder = \"G:/My Drive/dataset\"\n",
        "#         output_file = os.path.join(drive_folder, \"dataset_annotations.json\")\n",
        "\n",
        "#         # Simpan sebagai JSON\n",
        "#         with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "#             json.dump(annotations, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "#         print(f\"Dataset invoice berhasil disimpan ke {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset invoice berhasil disimpan ke data_tuning_inter.json\n"
          ]
        }
      ],
      "source": [
        "# # Konversi dataset 1 dan dataset 2\n",
        "# convert_dataset_local(data_tuning_local, \"data_tuning_local.json\")\n",
        "# convert_dataset_inter(data_tuning_inter, \"data_tuning_inter.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# python train.py --batch_size 16 --num_epochs 10 --lr 0.001 --train_data data_tuning_local.json data_tuning_inter.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "POST-PROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pre-Processing Hasil Text Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52b5q5KAQhWp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training BERT/NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

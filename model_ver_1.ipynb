{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets\n",
        "# !pip install easyocr\n",
        "# !pip install Pillow\n",
        "# !pip install numpy\n",
        "# !pip install matplotlib\n"
      ],
      "metadata": {
        "id": "l7AbYIPTK4Ei",
        "outputId": "dced5d04-bfe1-4526-f0bc-dcc3fa4bcdb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==0.4.1.post2 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==0.4.1.post2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "enc7HW6ji0rz"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import easyocr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/clovaai/CRAFT-pytorch.git"
      ],
      "metadata": {
        "id": "07me5aotGmoh",
        "outputId": "d030ff69-1036-40af-fcfe-61af0c498a35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CRAFT-pytorch'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 59 (delta 27), reused 24 (delta 24), pack-reused 23 (from 1)\u001b[K\n",
            "Receiving objects: 100% (59/59), 1.69 MiB | 23.66 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CRAFT-pytorch\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "_rgcmS7TGyp0",
        "outputId": "c5ec885e-e33e-419e-9b5f-62b940d818b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CRAFT-pytorch\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu124)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 2)) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Extraction**\n",
        "\n",
        "> using easyocr\n",
        "\n",
        "> support bahasa indonesia and english\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ged1zlumREAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from craft_text_detector import Craft\n",
        "\n",
        "craft = Craft(output_dir='outputs/', crop_type=\"poly\", cuda=False)  # Gunakan cuda=True jika pakai GPU\n",
        "\n",
        "def detect_text_craft(image):\n",
        "    # Jika gambar berupa PIL Image, konversi ke NumPy array\n",
        "    if isinstance(image, Image.Image):\n",
        "        image = np.array(image)\n",
        "\n",
        "    # Jika gambar masih dalam mode grayscale atau alpha, ubah ke BGR\n",
        "    if len(image.shape) == 2 or image.shape[2] == 1:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Jalankan deteksi teks\n",
        "    prediction_result = craft.detect_text(image)\n",
        "\n",
        "    # Ambil bounding boxes\n",
        "    boxes = prediction_result[\"boxes\"]\n",
        "\n",
        "    # Gambar bounding box\n",
        "    for box in boxes:\n",
        "        pts = box.reshape((-1, 1, 2)).astype(int)\n",
        "        cv2.polylines(image, [pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
        "\n",
        "    # Tampilkan hasil\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    return boxes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "crxLWM93oxy-",
        "outputId": "8245ce0e-cc65-4879-8e27-47a2aba97eec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'craft_text_detector'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bd0086115a3a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcraft_text_detector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCraft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcraft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCraft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outputs/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"poly\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Gunakan cuda=True jika pakai GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetect_text_craft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'craft_text_detector'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader = easyocr.Reader(['en', 'id'])\n",
        "\n",
        "def is_receipt(text, logic='AND'):\n",
        "    required_keywords = ['total', 'amount', 'jumlah', 'price', 'harga']\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    #diubah nanti jadinya ada yang and ada yang or\n",
        "    if logic == 'AND':\n",
        "        return all(keyword in text_lower for keyword in required_keywords)\n",
        "    elif logic == 'OR':\n",
        "        return any(keyword in text_lower for keyword in required_keywords)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid logic parameter. Use 'AND' or 'OR'.\")\n",
        "\n",
        "\n",
        "def process_image(image, logic='AND'):\n",
        "    # Convert PIL Image to numpy array\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # Extract text using EasyOCR\n",
        "    results = reader.readtext(image_np)\n",
        "\n",
        "    # Combine all detected text into a single string\n",
        "    extracted_text = ' '.join([result[1] for result in results])\n",
        "\n",
        "    # Check if the extracted text is a receipt\n",
        "    if is_receipt(extracted_text, logic=logic):\n",
        "        print(\"This is a valid receipt.\")\n",
        "        print(\"Extracted Text:\")\n",
        "        print(extracted_text)\n",
        "    else:\n",
        "        print(\"This is not a valid receipt.\")"
      ],
      "metadata": {
        "id": "-f01YTPk-JDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CORD-v2 dataset\n",
        "dataset = load_dataset(\"naver-clova-ix/cord-v2\")\n",
        "\n",
        "# Example: Process the first few images in the dataset\n",
        "for example in dataset['train'].select(range(5)):  # Process the first 5 examples\n",
        "    image = example['image']  # Get the PIL Image object\n",
        "    print(\"Processing image...\")\n",
        "\n",
        "    # Process the image with OR logic\n",
        "    detect_text_east(image)\n",
        "    process_image(image, logic='OR')\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Load international style dataset\n",
        "dataset_international = load_dataset(\"katanaml-org/invoices-donut-data-v1\")\n",
        "\n",
        "# Example: Process the first few images in the dataset_international\n",
        "for example_int in dataset_international['train'].select(range(5)):  # Process the first 5 examples\n",
        "    image_int = example_int['image']\n",
        "    print(\"Processing image international...\")\n",
        "\n",
        "    # Process the image with OR logic\n",
        "    detect_text_east(image_int)\n",
        "    process_image(image_int, logic='OR')\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "Akma0XMc07hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "35bdeWS26v1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hGlCXqf7RAyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FDRKJRv6tv0v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "l7AbYIPTK4Ei"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install Pillow\n",
        "# !pip install numpy\n",
        "# !pip install matplotlib\n",
        "# !pip install import_ipynb\n",
        "# !pip install tensorflow\n",
        "# !pip install tensorflow.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07me5aotGmoh",
        "outputId": "6032a295-01fa-4827-b688-29129cfd57a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/invoice-image-processing' already exists and is not an empty directory.\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 1 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (1/1), 187 bytes | 187.00 KiB/s, done.\n",
            "From https://github.com/fitristachan/invoice-image-processing\n",
            "   8c1d80f..e3c86be  main       -> origin/main\n",
            "Updating 8c1d80f..e3c86be\n",
            "Fast-forward\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the GitHub token from userdata\n",
        "myGithub = userdata.get('githubKey')\n",
        "\n",
        "!git clone https://{myGithub}@github.com/fitristachan/invoice-image-processing.git /content/invoice-image-processing\n",
        "!git -C invoice-image-processing pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "xAcGkB2eD3XN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c9446d-dbb9-420e-9e8c-6d546a107148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['invoice-image-processing.code-workspace', '__pycache__', 'requirements.txt', 'preprocessing.ipynb', '.git', 'data_etl_invoice.ipynb', 'Dataset', 'data_etl.py', 'model_ver_1.ipynb']\n",
            "[NbConvertApp] Converting notebook /content/invoice-image-processing/data_etl_invoice.ipynb to script\n",
            "[NbConvertApp] Writing 6902 bytes to /content/invoice-image-processing/data_etl.py\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('/content/invoice-image-processing')\n",
        "print(os.listdir('/content/invoice-image-processing'))\n",
        "\n",
        "!jupyter nbconvert --to script '/content/invoice-image-processing/data_etl_invoice.ipynb' --output data_etl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import import_ipynb\n",
        "import data_etl\n",
        "from data_etl import DatasetReceipt"
      ],
      "metadata": {
        "id": "n4RKPosRtYAJ"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "_rgcmS7TGyp0"
      },
      "outputs": [],
      "source": [
        "# !pip install torch\n",
        "# !pip install torchvision\n",
        "# !pip install scikit-image\n",
        "# !pip install scipy\n",
        "# !pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "Qo9Jl773p1xz"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import easyocr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ged1zlumREAq"
      },
      "source": [
        "**Text Extraction**\n",
        "\n",
        "> using easyocr\n",
        "\n",
        "> support bahasa indonesia and english\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "-f01YTPk-JDk"
      },
      "outputs": [],
      "source": [
        "reader = easyocr.Reader(['en', 'id'])\n",
        "\n",
        "def is_receipt(text, logic='AND'):\n",
        "    required_keywords = ['total', 'amount', 'jumlah', 'price', 'harga']\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    #diubah nanti jadinya ada yang and ada yang or\n",
        "    if logic == 'AND':\n",
        "        return all(keyword in text_lower for keyword in required_keywords)\n",
        "    elif logic == 'OR':\n",
        "        return any(keyword in text_lower for keyword in required_keywords)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid logic parameter. Use 'AND' or 'OR'.\")\n",
        "\n",
        "\n",
        "def process_image(image, logic='AND'):\n",
        "    # Convert PIL Image to numpy array\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # Extract text using EasyOCR\n",
        "    results = reader.readtext(image_np)\n",
        "\n",
        "    # Combine all detected text into a single string\n",
        "    extracted_text = ' '.join([result[1] for result in results])\n",
        "\n",
        "    # Check if the extracted text is a receipt\n",
        "    if is_receipt(extracted_text, logic=logic):\n",
        "        print(\"This is a valid receipt.\")\n",
        "        print(\"Extracted Text:\")\n",
        "        print(extracted_text)\n",
        "    else:\n",
        "        print(\"This is not a valid receipt.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "aiCMXKCupJ5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dataset\n",
        "dataset = DatasetReceipt(dataset_name=\"naver-clova-ix/cord-v2\", split=\"train\")\n",
        "\n",
        "# Verify dataset\n",
        "for i in range(5):\n",
        "    sample = dataset[i]\n",
        "    print(f\"Sample {i}:\")\n",
        "    print(\"Image Shape:\", sample[\"image\"].shape)\n",
        "    print(\"Label:\", sample[\"label\"])\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Create DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Verify DataLoader\n",
        "for batch in dataloader:\n",
        "    print(\"Batch Images Shape:\", batch[\"image\"].shape)\n",
        "    print(\"Batch Labels:\", batch[\"label\"])\n",
        "    break  # Print only the first batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vo6kdvMQ4lY",
        "outputId": "c55aca83-ea71-47f2-fad1-9121a0e1458b"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0:\n",
            "Image Shape: torch.Size([1, 600, 600])\n",
            "Label: -1\n",
            "--------------------------------------------------\n",
            "Sample 1:\n",
            "Image Shape: torch.Size([1, 600, 600])\n",
            "Label: -1\n",
            "--------------------------------------------------\n",
            "Sample 2:\n",
            "Image Shape: torch.Size([1, 600, 600])\n",
            "Label: -1\n",
            "--------------------------------------------------\n",
            "Sample 3:\n",
            "Image Shape: torch.Size([1, 600, 600])\n",
            "Label: -1\n",
            "--------------------------------------------------\n",
            "Sample 4:\n",
            "Image Shape: torch.Size([1, 600, 600])\n",
            "Label: -1\n",
            "--------------------------------------------------\n",
            "Batch Images Shape: torch.Size([8, 1, 600, 600])\n",
            "Batch Labels: tensor([-1, -1, -1, -1, -1, -1, -1, -1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Embedding(input_dim=5000, output_dim=128),\n",
        "#     tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "#     tf.keras.layers.LSTM(64),\n",
        "#     tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "#     tf.keras.layers.Dense(3, activation=\"softmax\")  # 3 kelas: menu, qty, price\n",
        "# ])\n",
        "\n",
        "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "uyjKutbMFsYp"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(padded, labels, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "52b5q5KAQhWp"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Gunakan dengan DataLoader untuk training\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# # Cek satu batch\n",
        "# for batch in dataloader:\n",
        "#     print(batch[\"image\"].shape)  # Harusnya (32, 1, 600, 600)\n",
        "#     break"
      ],
      "metadata": {
        "id": "ZKqvNij4G3WB"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "Akma0XMc07hb"
      },
      "outputs": [],
      "source": [
        "# # Load the CORD-v2 dataset\n",
        "# dataset = load_dataset(\"naver-clova-ix/cord-v2\")\n",
        "\n",
        "# # Example: Process the first few images in the dataset\n",
        "# for example in dataset['train'].select(range(5)):  # Process the first 5 examples\n",
        "#     image = example['image']  # Get the PIL Image object\n",
        "#     print(\"Processing image...\")\n",
        "\n",
        "#     # Process the image with OR logic\n",
        "#     process_image(image, logic='OR')\n",
        "#     print(\"-\" * 50)\n",
        "\n",
        "# # Load international style dataset\n",
        "# dataset_international = load_dataset(\"katanaml-org/invoices-donut-data-v1\")\n",
        "\n",
        "# # Example: Process the first few images in the dataset_international\n",
        "# for example_int in dataset_international['train'].select(range(5)):  # Process the first 5 examples\n",
        "#     image_int = example_int['image']\n",
        "#     print(\"Processing image international...\")\n",
        "\n",
        "#     # Process the image with OR logic\n",
        "#     process_image(image_int, logic='OR')\n",
        "#     print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "35bdeWS26v1s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "hGlCXqf7RAyY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "FDRKJRv6tv0v"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install transformers datasets scikit-learn seqeval\n# !pip install pandas numpy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:30:13.095287Z","iopub.execute_input":"2025-04-28T05:30:13.095527Z","iopub.status.idle":"2025-04-28T05:30:13.100084Z","shell.execute_reply.started":"2025-04-28T05:30:13.095505Z","shell.execute_reply":"2025-04-28T05:30:13.099423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\nimport transformers\n\nprint(transformers.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:30:13.100780Z","iopub.execute_input":"2025-04-28T05:30:13.101004Z","iopub.status.idle":"2025-04-28T05:30:25.926273Z","shell.execute_reply.started":"2025-04-28T05:30:13.100987Z","shell.execute_reply":"2025-04-28T05:30:25.925639Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load train dan validation dari masing-masing dataset\ncord_train = load_dataset(\"naver-clova-ix/cord-v2\", split=\"train\")\ncord_val = load_dataset(\"naver-clova-ix/cord-v2\", split=\"validation\")\n\ndonut_train = load_dataset(\"katanaml-org/invoices-donut-data-v1\", split=\"train\")\ndonut_val = load_dataset(\"katanaml-org/invoices-donut-data-v1\", split=\"validation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:30:25.927817Z","iopub.execute_input":"2025-04-28T05:30:25.928163Z","iopub.status.idle":"2025-04-28T05:30:56.612853Z","shell.execute_reply.started":"2025-04-28T05:30:25.928145Z","shell.execute_reply":"2025-04-28T05:30:56.611971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Label Definitions\nLABELS = [\n    \"O\",\n    \"B-ITEM\", \"I-ITEM\",\n    \"B-QUANTITY\", \"I-QUANTITY\",\n    \"B-PRICE\", \"I-PRICE\",\n    \"B-TOTAL\", \"I-TOTAL\",\n]\nlabel2id = {label: idx for idx, label in enumerate(LABELS)}\nid2label = {idx: label for label, idx in label2id.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:30:56.617167Z","iopub.execute_input":"2025-04-28T05:30:56.617500Z","iopub.status.idle":"2025-04-28T05:30:56.623641Z","shell.execute_reply.started":"2025-04-28T05:30:56.617472Z","shell.execute_reply":"2025-04-28T05:30:56.622796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom datasets import load_dataset\n\ndef extract_from_cord(example):\n    tokens = []\n    labels = []\n    parsed = json.loads(example['ground_truth'])\n\n    gt_parse = parsed.get('gt_parse', {})\n    \n    # Handle menu\n    for item in gt_parse.get('menu', []):\n        # print(f\"Item: {item}\")\n        # print(f\"Type of item: {type(item)}\")\n\n        # Extract and clean item\n        if(type(item) == \"dict\"):\n            item_name = item.get('nm', '').strip()\n            quantity = item.get('cnt', 0)\n            price = item.get('price', 0)\n        else:\n            continue\n\n        # Skip items with missing data\n        if not item_name or not quantity or not price:\n            continue\n\n        # Append to tokens and labels\n        tokens.append(item_name)\n        labels.append('B-ITEM')\n        tokens.append(str(quantity))\n        labels.append('B-QUANTITY')\n        tokens.append(str(price))\n        labels.append('B-PRICE')\n\n    def count_data(tokens):\n        return len(tokens)\n    \n    # Di dalam fungsi extract\n    # print(f\"Jumlah data akhir: {count_data(tokens)}\")\n\n    return tokens, labels\n\ndef extract_from_donut(example):\n    tokens = []\n    labels = []\n    parsed = json.loads(example['ground_truth'])\n\n    # Handle items\n    for item in parsed.get('gt_parse', {}).get('items', []):\n        # print(f\"Item: {item}\")\n        # print(f\"Type of item: {type(item)}\")\n        \n        item_name = item.get('item_desc', '').strip()\n        quantity = item.get('item_qty', 0)\n        price = item.get('item_gross_worth') or item.get('item_net_price') or 0\n\n        # Skip items with missing data\n        if not item_name or not quantity or not price:\n            continue\n\n        # Append to tokens and labels\n        tokens.append(item_name)\n        labels.append('B-ITEM')\n        tokens.append(str(quantity))\n        labels.append('B-QUANTITY')\n        tokens.append(str(price))\n        labels.append('B-PRICE')\n\n    # Handle total\n    summary_data = parsed.get('gt_parse', {}).get('summary', {})\n    total_gross = summary_data.get('total_gross_worth', 0)\n\n    tokens.append(str(total_gross))\n    labels.append('B-TOTAL')\n    \n    def count_data(tokens):\n        return len(tokens)\n    \n    # Di dalam fungsi extract\n    # print(f\"Jumlah data akhir: {count_data(tokens)}\")\n\n    return tokens, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:30:56.624242Z","iopub.execute_input":"2025-04-28T05:30:56.624531Z","iopub.status.idle":"2025-04-28T05:30:57.933594Z","shell.execute_reply.started":"2025-04-28T05:30:56.624500Z","shell.execute_reply":"2025-04-28T05:30:57.932767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd \n\n# tokens, labels = extract_from_cord(example)\n# df = pd.DataFrame({'token': tokens, 'label': labels})\n# print(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:30:57.934483Z","iopub.execute_input":"2025-04-28T05:30:57.934777Z","iopub.status.idle":"2025-04-28T05:30:59.173881Z","shell.execute_reply.started":"2025-04-28T05:30:57.934752Z","shell.execute_reply":"2025-04-28T05:30:59.173075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_tokens_train, all_labels_train = [], []\nall_tokens_val, all_labels_val = [], []\n\n# Train\nfor example in cord_train:\n    tokens, labels = extract_from_cord(example)\n    all_tokens_train.append(tokens)\n    all_labels_train.append(labels)\n\nfor example in donut_train:\n    tokens, labels = extract_from_donut(example)\n    all_tokens_train.append(tokens)\n    all_labels_train.append(labels)\n\n# Validation\nfor example in cord_val:\n    tokens, labels = extract_from_cord(example)\n    all_tokens_val.append(tokens)\n    all_labels_val.append(labels)\n\nfor example in donut_val:\n    tokens, labels = extract_from_donut(example)\n    all_tokens_val.append(tokens)\n    all_labels_val.append(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:30:59.174745Z","iopub.execute_input":"2025-04-28T05:30:59.175030Z","iopub.status.idle":"2025-04-28T05:31:55.643870Z","shell.execute_reply.started":"2025-04-28T05:30:59.175006Z","shell.execute_reply":"2025-04-28T05:31:55.643075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Pakai tokenizer multilingual\nMODEL_NAME = \"bert-base-multilingual-cased\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndef tokenize_and_align_labels(tokens_list, labels_list):\n    tokenized_inputs = []\n    aligned_labels = []\n\n    for tokens, labels in zip(tokens_list, labels_list):\n        input_tokens = []\n        input_labels = []\n\n        for token, label in zip(tokens, labels):\n            tokenized = tokenizer.tokenize(token)\n            input_tokens.extend(tokenized)\n            input_labels.extend([label] + [\"I-\" + label[2:]] * (len(tokenized) - 1))\n\n        # Convert to input ids\n        input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n        label_ids = [label2id[label] for label in input_labels]\n\n        tokenized_inputs.append(input_ids)\n        aligned_labels.append(label_ids)\n\n    return tokenized_inputs, aligned_labels\n\n# Tokenize Train\ninput_ids_train, label_ids_train = tokenize_and_align_labels(all_tokens_train, all_labels_train)\n\n# Tokenize Validation\ninput_ids_val, label_ids_val = tokenize_and_align_labels(all_tokens_val, all_labels_val)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:31:55.646238Z","iopub.execute_input":"2025-04-28T05:31:55.646504Z","iopub.status.idle":"2025-04-28T05:32:02.044135Z","shell.execute_reply.started":"2025-04-28T05:31:55.646484Z","shell.execute_reply":"2025-04-28T05:32:02.043554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass InvoiceNERDataset(Dataset):\n    def __init__(self, input_ids_list, label_ids_list, max_length=512):\n        self.input_ids_list = input_ids_list\n        self.label_ids_list = label_ids_list\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.input_ids_list)\n\n    def __getitem__(self, idx):\n        input_ids = self.input_ids_list[idx]\n        labels = self.label_ids_list[idx]\n\n        # Padding\n        attention_mask = [1] * len(input_ids)\n        padding_length = self.max_length - len(input_ids)\n\n        if padding_length > 0:\n            input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n            attention_mask = attention_mask + [0] * padding_length\n            labels = labels + [-100] * padding_length\n        else:\n            input_ids = input_ids[:self.max_length]\n            attention_mask = attention_mask[:self.max_length]\n            labels = labels[:self.max_length]\n\n        return {\n            \"input_ids\": torch.tensor(input_ids),\n            \"attention_mask\": torch.tensor(attention_mask),\n            \"labels\": torch.tensor(labels),\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:32:02.044873Z","iopub.execute_input":"2025-04-28T05:32:02.045342Z","iopub.status.idle":"2025-04-28T05:32:02.051933Z","shell.execute_reply.started":"2025-04-28T05:32:02.045316Z","shell.execute_reply":"2025-04-28T05:32:02.051360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset\ntrain_dataset = InvoiceNERDataset(input_ids_train, label_ids_train)\nval_dataset = InvoiceNERDataset(input_ids_val, label_ids_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:32:02.052601Z","iopub.execute_input":"2025-04-28T05:32:02.052816Z","iopub.status.idle":"2025-04-28T05:32:02.077802Z","shell.execute_reply.started":"2025-04-28T05:32:02.052800Z","shell.execute_reply":"2025-04-28T05:32:02.077126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hyperparams = {\n    \"output_dir\": \"./bert-receipt-model\",\n    \"evaluation_strategy\": \"steps\",\n    \"save_strategy\": \"steps\",\n    \"save_steps\": 500,\n    \"eval_steps\": 500,\n    \"logging_steps\": 100,\n    \"per_device_train_batch_size\": 8,\n    \"per_device_eval_batch_size\": 8,\n    \"num_train_epochs\": 5,\n    \"weight_decay\": 0.01,\n    \"learning_rate\": 5e-5,\n    \"warmup_steps\": 500,\n    \"load_best_model_at_end\": True,\n    \"metric_for_best_model\": \"loss\",  # atau nanti bisa pakai f1\n    \"greater_is_better\": False,       # karena loss makin kecil makin bagus\n    \"save_total_limit\": 2,            # save max 2 checkpoint aja\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:32:02.078579Z","iopub.execute_input":"2025-04-28T05:32:02.078869Z","iopub.status.idle":"2025-04-28T05:32:02.099107Z","shell.execute_reply.started":"2025-04-28T05:32:02.078853Z","shell.execute_reply":"2025-04-28T05:32:02.098610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BertForTokenClassification, Trainer, TrainingArguments, EarlyStoppingCallback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:32:02.099661Z","iopub.execute_input":"2025-04-28T05:32:02.099849Z","iopub.status.idle":"2025-04-28T05:32:28.760604Z","shell.execute_reply.started":"2025-04-28T05:32:02.099835Z","shell.execute_reply":"2025-04-28T05:32:28.760000Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ”¥ Model\nmodel = BertForTokenClassification.from_pretrained(\n    \"bert-base-multilingual-cased\",\n    num_labels=len(LABELS),\n    id2label=id2label,\n    label2id=label2id,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:32:28.761347Z","iopub.execute_input":"2025-04-28T05:32:28.761948Z","iopub.status.idle":"2025-04-28T05:32:32.250899Z","shell.execute_reply.started":"2025-04-28T05:32:28.761903Z","shell.execute_reply":"2025-04-28T05:32:32.250360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=hyperparams[\"output_dir\"],\n    eval_strategy=hyperparams[\"evaluation_strategy\"],\n    save_strategy=hyperparams[\"save_strategy\"],\n    save_steps=hyperparams[\"save_steps\"],\n    eval_steps=hyperparams[\"eval_steps\"],\n    logging_steps=hyperparams[\"logging_steps\"],\n    per_device_train_batch_size=hyperparams[\"per_device_train_batch_size\"],\n    per_device_eval_batch_size=hyperparams[\"per_device_eval_batch_size\"],\n    num_train_epochs=hyperparams[\"num_train_epochs\"],\n    weight_decay=hyperparams[\"weight_decay\"],\n    learning_rate=hyperparams[\"learning_rate\"],\n    warmup_steps=hyperparams[\"warmup_steps\"],\n    load_best_model_at_end=hyperparams[\"load_best_model_at_end\"],\n    metric_for_best_model=hyperparams[\"metric_for_best_model\"],\n    greater_is_better=hyperparams[\"greater_is_better\"],\n    save_total_limit=hyperparams[\"save_total_limit\"],\n    logging_dir=\"./logs\",\n    report_to=\"none\",  # disable wandb\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:32:32.251530Z","iopub.execute_input":"2025-04-28T05:32:32.251725Z","iopub.status.idle":"2025-04-28T05:32:32.286721Z","shell.execute_reply.started":"2025-04-28T05:32:32.251710Z","shell.execute_reply":"2025-04-28T05:32:32.286068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    processing_class=tokenizer,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:32:32.287408Z","iopub.execute_input":"2025-04-28T05:32:32.287653Z","iopub.status.idle":"2025-04-28T05:32:32.750456Z","shell.execute_reply.started":"2025-04-28T05:32:32.287636Z","shell.execute_reply":"2025-04-28T05:32:32.749851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:32:32.751124Z","iopub.execute_input":"2025-04-28T05:32:32.751320Z","iopub.status.idle":"2025-04-28T05:38:48.408933Z","shell.execute_reply.started":"2025-04-28T05:32:32.751305Z","shell.execute_reply":"2025-04-28T05:38:48.408348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ”¥ Save final model + tokenizer\ntrainer.save_model(hyperparams[\"output_dir\"])\ntokenizer.save_pretrained(hyperparams[\"output_dir\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:38:48.409685Z","iopub.execute_input":"2025-04-28T05:38:48.409900Z","iopub.status.idle":"2025-04-28T05:38:50.334825Z","shell.execute_reply.started":"2025-04-28T05:38:48.409884Z","shell.execute_reply":"2025-04-28T05:38:50.334221Z"}},"outputs":[],"execution_count":null}]}
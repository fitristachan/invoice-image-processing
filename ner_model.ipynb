{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install spacy datasets\n# !python -m spacy download en_core_web_sm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T20:07:00.282952Z","iopub.execute_input":"2025-05-07T20:07:00.283531Z","iopub.status.idle":"2025-05-07T20:07:00.287081Z","shell.execute_reply.started":"2025-05-07T20:07:00.283503Z","shell.execute_reply":"2025-05-07T20:07:00.286268Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import spacy\nfrom spacy.training.example import Example\nfrom datasets import load_dataset\nimport json\n\n# ---------- Ekstraksi ----------\ndef extract_from_cord(example):\n    tokens, labels = [], []\n    parsed = json.loads(example['ground_truth'])\n    for item in parsed.get('gt_parse', {}).get('menu', []):\n        if isinstance(item, dict):\n            # Handle item_name as list or str\n            item_name_raw = item.get('nm', '')\n            if isinstance(item_name_raw, list):\n                item_name = \" \".join(item_name_raw).strip()\n            elif isinstance(item_name_raw, str):\n                item_name = item_name_raw.strip()\n            else:\n                item_name = ''\n\n            quantity = item.get('cnt', 0)\n            price = item.get('price', 0)\n\n            if item_name and quantity and price:\n                tokens += [item_name, str(quantity), str(price)]\n                labels += ['B-ITEM', 'B-QUANTITY', 'B-PRICE']\n    return tokens, labels\n\ndef extract_from_donut(example):\n    tokens, labels = [], []\n    parsed = json.loads(example['ground_truth'])\n    for item in parsed.get('gt_parse', {}).get('items', []):\n        item_name = item.get('item_desc', '').strip()\n        quantity = item.get('item_qty', 0)\n        price = item.get('item_gross_worth') or item.get('item_net_price') or 0\n        if item_name and quantity and price:\n            tokens += [item_name, str(quantity), str(price)]\n            labels += ['B-ITEM', 'B-QUANTITY', 'B-PRICE']\n    return tokens, labels\n\ndef convert_tokens_to_spacy_format(tokens, labels):\n    text = \" \".join(tokens)\n    entities = []\n    start = 0\n    for token, label in zip(tokens, labels):\n        start = text.find(token, start)\n        if start == -1:\n            continue\n        end = start + len(token)\n        entities.append((start, end, label.replace(\"B-\", \"\")))\n        start = end\n    return (text, {\"entities\": entities})\n\n# ---------- Load dataset ----------\ncord = load_dataset(\"naver-clova-ix/cord-v2\")\ndonut = load_dataset(\"katanaml-org/invoices-donut-data-v1\")\n\ndef make_examples(dataset, extractor_fn):\n    examples = []\n    for ex in dataset:\n        tokens, labels = extractor_fn(ex)\n        if tokens:\n            examples.append(convert_tokens_to_spacy_format(tokens, labels))\n    return examples\n\ntrain_examples = make_examples(cord[\"train\"], extract_from_cord) + make_examples(donut[\"train\"], extract_from_donut)\nval_examples = make_examples(cord[\"validation\"], extract_from_cord) + make_examples(donut[\"validation\"], extract_from_donut)\ntest_examples = make_examples(cord[\"test\"], extract_from_cord) + make_examples(donut[\"test\"], extract_from_donut)\n\nprint(f\"Train: {len(train_examples)}, Val: {len(val_examples)}, Test: {len(test_examples)}\")\n\n# ---------- Training spaCy ----------\nnlp = spacy.blank(\"en\")\nner = nlp.add_pipe(\"ner\")\n\n# Tambah label\nfor _, ann in train_examples:\n    for _, _, label in ann[\"entities\"]:\n        ner.add_label(label)\n\n# Training\noptimizer = nlp.begin_training()\nfor i in range(20):\n    losses = {}\n    for text, annotations in train_examples:\n        doc = nlp.make_doc(text)\n        example = Example.from_dict(doc, annotations)\n        nlp.update([example], drop=0.35, losses=losses)\n    print(f\"Epoch {i+1}: Loss = {losses['ner']:.4f}\")\n\n# Simpan model\nnlp.to_disk(\"ner_receipt_model\")\n\n# ---------- Evaluasi ----------\ndef evaluate_ner(nlp, examples):\n    tp = {\"ITEM\": 0, \"QUANTITY\": 0, \"PRICE\": 0}\n    fp = {\"ITEM\": 0, \"QUANTITY\": 0, \"PRICE\": 0}\n    fn = {\"ITEM\": 0, \"QUANTITY\": 0, \"PRICE\": 0}\n\n    for text, ann in examples:\n        pred = nlp(text)\n        pred_ents = {(ent.start_char, ent.end_char, ent.label_) for ent in pred.ents}\n        true_ents = {(start, end, label) for start, end, label in ann[\"entities\"]}\n\n        for ent in pred_ents:\n            if ent in true_ents:\n                tp[ent[2]] += 1\n            else:\n                fp[ent[2]] += 1\n        for ent in true_ents:\n            if ent not in pred_ents:\n                fn[ent[2]] += 1\n\n    print(\"\\n--- Evaluation Report ---\")\n    for label in tp:\n        precision = tp[label] / (tp[label] + fp[label] + 1e-6)\n        recall = tp[label] / (tp[label] + fn[label] + 1e-6)\n        f1 = 2 * precision * recall / (precision + recall + 1e-6)\n        print(f\"{label}: P={precision:.2f} R={recall:.2f} F1={f1:.2f}\")\n\nprint(\"\\n✅ Validation Evaluation:\")\nevaluate_ner(nlp, val_examples)\n\nprint(\"\\n✅ Test Evaluation:\")\nevaluate_ner(nlp, test_examples)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T20:09:22.012268Z","iopub.execute_input":"2025-05-07T20:09:22.013043Z","iopub.status.idle":"2025-05-07T20:17:56.528885Z","shell.execute_reply.started":"2025-05-07T20:09:22.013014Z","shell.execute_reply":"2025-05-07T20:17:56.527969Z"}},"outputs":[{"name":"stdout","text":"Train: 827, Val: 100, Test: 81\n","output_type":"stream"},{"name":"stderr","text":"[2025-05-07 20:10:25,080] [INFO] Created vocabulary\n[2025-05-07 20:10:25,081] [INFO] Finished initializing nlp object\n/usr/local/lib/python3.11/dist-packages/thinc/layers/layernorm.py:31: RuntimeWarning: divide by zero encountered in reciprocal\n  d_xhat = N * dY - sum_dy - dist * var ** (-1.0) * sum_dy_dist\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Loss = 1660.3038\nEpoch 2: Loss = 516.5396\nEpoch 3: Loss = 329.6005\nEpoch 4: Loss = 288.5896\nEpoch 5: Loss = 253.7034\nEpoch 6: Loss = 230.5863\nEpoch 7: Loss = 217.8163\nEpoch 8: Loss = 152.0029\nEpoch 9: Loss = 140.4869\nEpoch 10: Loss = 98.9411\nEpoch 11: Loss = 117.5162\nEpoch 12: Loss = 57.2309\nEpoch 13: Loss = 87.6488\nEpoch 14: Loss = 117.0263\nEpoch 15: Loss = 130.9066\nEpoch 16: Loss = 63.1573\nEpoch 17: Loss = 40.5748\nEpoch 18: Loss = 69.2594\nEpoch 19: Loss = 87.4858\nEpoch 20: Loss = 88.2810\n\n✅ Validation Evaluation:\n\n--- Evaluation Report ---\nITEM: P=0.99 R=0.98 F1=0.99\nQUANTITY: P=1.00 R=0.99 F1=0.99\nPRICE: P=1.00 R=0.99 F1=0.99\n\n✅ Test Evaluation:\n\n--- Evaluation Report ---\nITEM: P=0.99 R=0.99 F1=0.99\nQUANTITY: P=1.00 R=0.99 F1=1.00\nPRICE: P=1.00 R=1.00 F1=1.00\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load(\"ner_receipt_model\")\ntext = \"Nasi Goreng 2 25000\"\n\ndoc = nlp(text)\nfor ent in doc.ents:\n    print(ent.text, ent.label_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T20:20:06.462127Z","iopub.execute_input":"2025-05-07T20:20:06.462791Z","iopub.status.idle":"2025-05-07T20:20:06.807912Z","shell.execute_reply.started":"2025-05-07T20:20:06.462763Z","shell.execute_reply":"2025-05-07T20:20:06.807135Z"}},"outputs":[{"name":"stdout","text":"Nasi Goreng ITEM\n2 QUANTITY\n25000 PRICE\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import shutil\n\n# Menyimpan model ke dalam format zip\nshutil.make_archive(\"ner_receipt_model\", 'zip', \"ner_receipt_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T20:21:58.551912Z","iopub.execute_input":"2025-05-07T20:21:58.552616Z","iopub.status.idle":"2025-05-07T20:21:58.770248Z","shell.execute_reply.started":"2025-05-07T20:21:58.552586Z","shell.execute_reply":"2025-05-07T20:21:58.769621Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/ner_receipt_model.zip'"},"metadata":{}}],"execution_count":7}]}